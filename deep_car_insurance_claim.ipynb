{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-23T00:58:31.101271Z",
     "end_time": "2023-05-23T00:58:31.104182Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from torch.utils.data import dataloader, Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "       KIDSDRIV  AGE  HOMEKIDS  YOJ  INCOME PARENT1  HOME_VAL MSTATUS GENDER   \n0             0   60         0   11   67349      NO         0      NO      M  \\\n1             0   43         0   11   91449      NO    257252      NO      M   \n2             0   48         0   11   52881      NO         0      NO      M   \n3             0   35         1   10   16039      NO    124191     YES      F   \n4             0   51         0   14       0      NO    306251     YES      M   \n...         ...  ...       ...  ...     ...     ...       ...     ...    ...   \n10297         1   45         2    9  164669      NO    386273     YES      M   \n10298         0   46         0    9  107204      NO    332591     YES      M   \n10299         0   48         0   15   39837      NO    170611     YES      F   \n10300         0   50         0    7   43445      NO    149248     YES      F   \n10301         0   52         0   11   53235      NO    197017     YES      F   \n\n         EDUCATION  ...    CAR_TYPE  RED_CAR OLDCLAIM  CLM_FREQ  REVOKED   \n0              PHD  ...     MINIVAN      YES     4461         2       NO  \\\n1       HIGHSCHOOL  ...     MINIVAN      YES        0         0       NO   \n2        BACHELORS  ...         VAN      YES        0         0       NO   \n3       HIGHSCHOOL  ...         SUV       NO    38690         2       NO   \n4      <HIGHSCHOOL  ...     MINIVAN      YES        0         0       NO   \n...            ...  ...         ...      ...      ...       ...      ...   \n10297          PHD  ...     MINIVAN       NO        0         0       NO   \n10298      MASTERS  ...  PANELTRUCK       NO        0         0       NO   \n10299  <HIGHSCHOOL  ...         SUV       NO        0         0       NO   \n10300    BACHELORS  ...     MINIVAN       NO        0         0       NO   \n10301   HIGHSCHOOL  ...     MINIVAN       NO        0         0       NO   \n\n      MVR_PTS CLM_AMT  CAR_AGE  CLAIM_FLAG   AREA  \n0           3       0       18           0  URBAN  \n1           0       0        1           0  URBAN  \n2           2       0       10           0  URBAN  \n3           3       0       10           0  URBAN  \n4           0       0        6           0  URBAN  \n...       ...     ...      ...         ...    ...  \n10297       2       0       17           0  URBAN  \n10298       0       0        1           0  URBAN  \n10299       0       0        1           0  URBAN  \n10300       0       0       11           0  URBAN  \n10301       0       0        9           0  RURAL  \n\n[10302 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>KIDSDRIV</th>\n      <th>AGE</th>\n      <th>HOMEKIDS</th>\n      <th>YOJ</th>\n      <th>INCOME</th>\n      <th>PARENT1</th>\n      <th>HOME_VAL</th>\n      <th>MSTATUS</th>\n      <th>GENDER</th>\n      <th>EDUCATION</th>\n      <th>...</th>\n      <th>CAR_TYPE</th>\n      <th>RED_CAR</th>\n      <th>OLDCLAIM</th>\n      <th>CLM_FREQ</th>\n      <th>REVOKED</th>\n      <th>MVR_PTS</th>\n      <th>CLM_AMT</th>\n      <th>CAR_AGE</th>\n      <th>CLAIM_FLAG</th>\n      <th>AREA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>60</td>\n      <td>0</td>\n      <td>11</td>\n      <td>67349</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>M</td>\n      <td>PHD</td>\n      <td>...</td>\n      <td>MINIVAN</td>\n      <td>YES</td>\n      <td>4461</td>\n      <td>2</td>\n      <td>NO</td>\n      <td>3</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>11</td>\n      <td>91449</td>\n      <td>NO</td>\n      <td>257252</td>\n      <td>NO</td>\n      <td>M</td>\n      <td>HIGHSCHOOL</td>\n      <td>...</td>\n      <td>MINIVAN</td>\n      <td>YES</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>48</td>\n      <td>0</td>\n      <td>11</td>\n      <td>52881</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>M</td>\n      <td>BACHELORS</td>\n      <td>...</td>\n      <td>VAN</td>\n      <td>YES</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>2</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>35</td>\n      <td>1</td>\n      <td>10</td>\n      <td>16039</td>\n      <td>NO</td>\n      <td>124191</td>\n      <td>YES</td>\n      <td>F</td>\n      <td>HIGHSCHOOL</td>\n      <td>...</td>\n      <td>SUV</td>\n      <td>NO</td>\n      <td>38690</td>\n      <td>2</td>\n      <td>NO</td>\n      <td>3</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>51</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>306251</td>\n      <td>YES</td>\n      <td>M</td>\n      <td>&lt;HIGHSCHOOL</td>\n      <td>...</td>\n      <td>MINIVAN</td>\n      <td>YES</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10297</th>\n      <td>1</td>\n      <td>45</td>\n      <td>2</td>\n      <td>9</td>\n      <td>164669</td>\n      <td>NO</td>\n      <td>386273</td>\n      <td>YES</td>\n      <td>M</td>\n      <td>PHD</td>\n      <td>...</td>\n      <td>MINIVAN</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>2</td>\n      <td>0</td>\n      <td>17</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>10298</th>\n      <td>0</td>\n      <td>46</td>\n      <td>0</td>\n      <td>9</td>\n      <td>107204</td>\n      <td>NO</td>\n      <td>332591</td>\n      <td>YES</td>\n      <td>M</td>\n      <td>MASTERS</td>\n      <td>...</td>\n      <td>PANELTRUCK</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>10299</th>\n      <td>0</td>\n      <td>48</td>\n      <td>0</td>\n      <td>15</td>\n      <td>39837</td>\n      <td>NO</td>\n      <td>170611</td>\n      <td>YES</td>\n      <td>F</td>\n      <td>&lt;HIGHSCHOOL</td>\n      <td>...</td>\n      <td>SUV</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>10300</th>\n      <td>0</td>\n      <td>50</td>\n      <td>0</td>\n      <td>7</td>\n      <td>43445</td>\n      <td>NO</td>\n      <td>149248</td>\n      <td>YES</td>\n      <td>F</td>\n      <td>BACHELORS</td>\n      <td>...</td>\n      <td>MINIVAN</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>URBAN</td>\n    </tr>\n    <tr>\n      <th>10301</th>\n      <td>0</td>\n      <td>52</td>\n      <td>0</td>\n      <td>11</td>\n      <td>53235</td>\n      <td>NO</td>\n      <td>197017</td>\n      <td>YES</td>\n      <td>F</td>\n      <td>HIGHSCHOOL</td>\n      <td>...</td>\n      <td>MINIVAN</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NO</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>RURAL</td>\n    </tr>\n  </tbody>\n</table>\n<p>10302 rows Ã— 25 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/car_insurance_claim.csv\")\n",
    "\n",
    "for col in [\"INCOME\",\"HOME_VAL\",\"BLUEBOOK\",\"OLDCLAIM\", \"CLM_AMT\",]:\n",
    "    df[col] = df[col].replace(\"[^.0-9]\", \"\", regex=True).astype(float).fillna(0.0)\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    df[col] = df[col].str.upper().replace(\"Z_\", \"\", regex=True).replace(\"[^A-Z<]\", \"\", regex=True)\n",
    "\n",
    "df.drop(labels=[\"ID\",\"BIRTH\"], axis=1, inplace=True)\n",
    "\n",
    "df[\"OCCUPATION\"].fillna(\"OTHER\", inplace=True)\n",
    "for col in [\"AGE\",\"YOJ\",\"CAR_AGE\"]:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "for col in df.select_dtypes(include=[float]):\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "df[\"URBANICITY\"] = df[\"URBANICITY\"].map({\"HIGHLYURBANURBAN\":\"URBAN\", \"HIGHLYRURALRURAL\":\"RURAL\"})\n",
    "df.rename(columns={\"URBANICITY\": \"AREA\"}, inplace=True)\n",
    "\n",
    "categorical_features = [\"EDUCATION\", \"KIDSDRIV\", \"HOMEKIDS\", \"CAR_TYPE\", \"OCCUPATION\", \"MVR_PTS\"]\n",
    "boolean_features = [\"CAR_USE\", \"REVOKED\", \"RED_CAR\", \"GENDER\", \"MSTATUS\", \"AREA\", \"PARENT1\", \"CLAIM_FLAG\"]\n",
    "numerical_features = [\"AGE\", \"YOJ\", \"INCOME\", \"HOME_VAL\", \"TRAVTIME\", \"BLUEBOOK\", \"TIF\", \"OLDCLAIM\", \"CLM_FREQ\", \"CLM_AMT\", \"CAR_AGE\"]\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T00:58:31.104182Z",
     "end_time": "2023-05-23T00:58:31.350315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "[(5, 3), (5, 3), (6, 3), (6, 3), (9, 5), (14, 7)]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df[categorical_features].apply(LabelEncoder().fit_transform)\n",
    "df_bool = df[boolean_features].apply(LabelEncoder().fit_transform)\n",
    "df_cont = df[numerical_features]\n",
    "\n",
    "cat_tensor = torch.tensor(df_cat.values, dtype=torch.float)\n",
    "bool_tensor = torch.tensor(df_bool.values, dtype=torch.long)\n",
    "cont_tensor = torch.tensor(df_cont.values, dtype=torch.float)\n",
    "\n",
    "embedding_sizes = [(df_cat[col].nunique(), min(50, (df_cat[col].nunique()+1)//2)) for col in df_cat]\n",
    "embedding_sizes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T00:58:31.351316Z",
     "end_time": "2023-05-23T00:58:31.375731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 48\u001B[0m\n\u001B[0;32m     45\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# compute reconstructions\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcat_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcont_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbool_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# compute training reconstruction loss\u001B[39;00m\n\u001B[0;32m     51\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m criterion(outputs, torch\u001B[38;5;241m.\u001B[39mcat([cat_tensor, cont_tensor, bool_tensor], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\repos\\attention-mixed-type-clustering\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[41], line 19\u001B[0m, in \u001B[0;36mMixedTypeClusteringModel.forward\u001B[1;34m(self, x_cat, x_bool, x_cont)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_cat, x_bool, x_cont):\n\u001B[1;32m---> 19\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43me\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_cat\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43me\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     20\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(x, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((x, x_bool), \u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[1;32mIn[41], line 19\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x_cat, x_bool, x_cont):\n\u001B[1;32m---> 19\u001B[0m     x \u001B[38;5;241m=\u001B[39m [\u001B[43me\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_cat\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m i,e \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings)]\n\u001B[0;32m     20\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(x, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((x, x_bool), \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\repos\\attention-mixed-type-clustering\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\repos\\attention-mixed-type-clustering\\venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\repos\\attention-mixed-type-clustering\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2210\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2204\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2205\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2206\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2207\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2208\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2209\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "class MixedTypeClusteringModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num, dim) for num, dim in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        in_dim = n_emb + len(boolean_features) + len(numerical_features)\n",
    "\n",
    "        self.encoder_input_layer = nn.Linear(\n",
    "            in_features=25, out_features=16\n",
    "        )\n",
    "        self.hidden_layer = nn.Linear(\n",
    "            in_features=16, out_features=16\n",
    "        )\n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features=16, out_features=25\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cat, x_bool, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = torch.cat((x, x_bool), 1)\n",
    "        x = torch.cat((x, x_cont), 1)\n",
    "\n",
    "        x = self.encoder_input_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.decoder_output_layer(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "model = MixedTypeClusteringModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # reset the gradients back to zero\n",
    "    # PyTorch accumulates gradients on subsequent backward passes\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # compute reconstructions\n",
    "    outputs = model(cat_tensor, cont_tensor, bool_tensor)\n",
    "\n",
    "    # compute training reconstruction loss\n",
    "    train_loss = criterion(outputs, torch.cat([cat_tensor, cont_tensor, bool_tensor], dim=1))\n",
    "\n",
    "    # compute accumulated gradients\n",
    "    train_loss.backward()\n",
    "\n",
    "    # perform parameter update based on current gradients\n",
    "    optimizer.step()\n",
    "\n",
    "    # add the mini-batch training loss to epoch loss\n",
    "    loss = train_loss.item()\n",
    "\n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T19:41:17.462517600Z",
     "start_time": "2023-05-20T19:41:17.391614900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
