\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\babel@aux{english}{}
\citation{mixed_type_survey_2019}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{uci_ml_rpo}
\citation{abalone}
\citation{auction_verification}
\citation{bank_marketing}
\citation{breast_cancer}
\citation{census_income}
\citation{credit_approval}
\citation{heart_disease}
\citation{abalone}
\citation{scikit_learn}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Foundation}{4}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Methodology}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Datasets}{4}{}\protected@file@percent }
\newlabel{Datasets}{{3.1.1}{4}{}{}{}}
\citation{pytorch}
\citation{scipy}
\citation{scikit_learn}
\citation{scikit_learn}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Evaluation}{5}{}\protected@file@percent }
\citation{kmeans}
\citation{kmeans_np_hard}
\citation{kmeans_np_hard}
\citation{kmeans_lloyd}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Classical Methods for clustering Mixed-Type data}{6}{}\protected@file@percent }
\newlabel{Classical Methods for clustering Mixed-Type data}{{3.2}{6}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}k-means}{6}{}\protected@file@percent }
\citation{pattern_recognition_machine_learning}
\citation{kmodes}
\citation{kmodes}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}k-modes}{7}{}\protected@file@percent }
\newlabel{k-modes}{{3.2.2}{7}{}{}{}}
\citation{kmodes}
\citation{kmodes}
\citation{kmodes}
\citation{kmodes}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}k-prototypes}{8}{}\protected@file@percent }
\citation{kmodes}
\citation{gower}
\citation{gower}
\citation{gower}
\citation{gower}
\citation{gower}
\citation{algorithms_for_clustering_data}
\citation{philip_ottaway}
\citation{algorithms_for_clustering_data}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Gower distance}{9}{}\protected@file@percent }
\citation{neural_network_1943}
\citation{perceptron}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Score $s_{ijk}$ and quantity $\delta _{ijk}$ of a feature $k$ on two instances $x_i$ and $x_j$. Presence of a feature is denoted by "+" and absence by "-". \cite  {gower}}}{10}{}\protected@file@percent }
\newlabel{gower_dichotomous}{{3.1}{10}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Deep Clustering}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Neural Networks}{10}{}\protected@file@percent }
\citation{hidden_layer_backprop}
\citation{neural_networks_pattern_recognition}
\citation{neural_networks_pattern_recognition}
\citation{activation_functions}
\citation{activation_functions}
\citation{neural_networks_pattern_recognition}
\citation{activation_functions}
\citation{activation_functions}
\citation{activation_functions}
\citation{activation_functions}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Autoencoders}{12}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An illustration of the step function, the logistic sigmoid, the ReLU and the Leaky ReLU activaiton functions.}}{13}{}\protected@file@percent }
\newlabel{activation_functions}{{3.2}{13}{}{}{}}
\citation{kmodes}
\citation{kmodes}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Attention in Mixed-Type Clustering}{14}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Autoencoder and k-means}{14}{}\protected@file@percent }
\citation{bahdanau}
\citation{attention_is_all_you_need}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Column Embeddings}{15}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Attention}{15}{}\protected@file@percent }
\citation{attention_is_all_you_need}
\citation{tab_transformer}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments}{18}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Experiments}{{5}{18}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Comparison of classical Clustering Methods}{18}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Comparsion of Normalized Mutual Information of various classical methods on clustering mixed-type datasets.}}{18}{}\protected@file@percent }
\newlabel{classical_comparison_nmi}{{5.1}{18}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Comparsion of Accuracy of various classical methods on clustering mixed-type datasets.}}{19}{}\protected@file@percent }
\newlabel{classical_comparison_acc}{{5.2}{19}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Number of instances of each target class of each dataset used.}}{19}{}\protected@file@percent }
\newlabel{class_imbalance}{{5.3}{19}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Comparsion of Normalized Mutual Information of various Autoencoder architectures combined with k-means on clustering mixed-type datasets.}}{20}{}\protected@file@percent }
\newlabel{ae_architecture_comparison_nmi}{{5.4}{20}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Comparsion of Accuracy of various Autoencoder architectures combined with k-means on clustering mixed-type datasets.}}{20}{}\protected@file@percent }
\newlabel{ae_architecture_comparison_acc}{{5.5}{20}{}{}{}}
\bibstyle{plain}
\bibdata{dmmdbstmpl}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{21}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{mixed_type_survey_2019}{1}
\bibcite{bahdanau}{2}
\bibcite{neural_networks_pattern_recognition}{3}
\bibcite{pattern_recognition_machine_learning}{4}
\bibcite{activation_functions}{5}
\bibcite{gower}{6}
\bibcite{tab_transformer}{7}
\bibcite{kmodes}{8}
\bibcite{algorithms_for_clustering_data}{9}
\bibcite{heart_disease}{10}
\bibcite{census_income}{11}
\bibcite{kmeans_lloyd}{12}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{22}{}\protected@file@percent }
\bibcite{kmeans}{13}
\bibcite{kmeans_np_hard}{14}
\bibcite{uci_ml_rpo}{15}
\bibcite{neural_network_1943}{16}
\bibcite{bank_marketing}{17}
\bibcite{abalone}{18}
\bibcite{auction_verification}{19}
\bibcite{pytorch}{20}
\bibcite{scikit_learn}{21}
\bibcite{philip_ottaway}{22}
\bibcite{credit_approval}{23}
\bibcite{perceptron}{24}
\bibcite{hidden_layer_backprop}{25}
\bibcite{attention_is_all_you_need}{26}
\bibcite{scipy}{27}
\bibcite{breast_cancer}{28}
\gdef \@abspage@last{27}
