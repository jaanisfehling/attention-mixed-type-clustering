\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}Introduction}{2}{}%
\contentsline {chapter}{\numberline {2}Related Work}{3}{}%
\contentsline {chapter}{\numberline {3}Foundation}{4}{}%
\contentsline {section}{\numberline {3.1}Methodology}{4}{}%
\contentsline {subsection}{\numberline {3.1.1}Datasets}{4}{}%
\contentsline {subsection}{\numberline {3.1.2}Evaluation}{5}{}%
\contentsline {section}{\numberline {3.2}Classical Methods for clustering Mixed-Type data}{6}{}%
\contentsline {subsection}{\numberline {3.2.1}k-means}{6}{}%
\contentsline {subsection}{\numberline {3.2.2}k-modes}{7}{}%
\contentsline {subsection}{\numberline {3.2.3}k-prototypes}{8}{}%
\contentsline {subsection}{\numberline {3.2.4}Gower distance}{9}{}%
\contentsline {section}{\numberline {3.3}Deep Clustering}{10}{}%
\contentsline {subsection}{\numberline {3.3.1}Neural Networks}{10}{}%
\contentsline {subsection}{\numberline {3.3.2}Autoencoder}{14}{}%
\contentsline {chapter}{\numberline {4}Attention in Mixed-Type Clustering}{16}{}%
\contentsline {section}{\numberline {4.1}Autoencoder and k-means}{16}{}%
\contentsline {section}{\numberline {4.2}Column Embeddings}{17}{}%
\contentsline {section}{\numberline {4.3}Attention}{18}{}%
\contentsline {section}{\numberline {4.4}Transformer}{22}{}%
\contentsline {subsection}{\numberline {4.4.1}FT-Transformer}{22}{}%
\contentsline {chapter}{\numberline {5}Experiments}{26}{}%
\contentsline {section}{\numberline {5.1}Comparison of classical Clustering Methods}{26}{}%
\contentsline {chapter}{\numberline {6}Conclusion}{30}{}%
\contentsline {chapter}{Bibliography}{31}{}%
