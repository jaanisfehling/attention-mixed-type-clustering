{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from duped_modules.dcn_duped import DCNDuped\n",
    "from duped_modules.dec_duped import DECDuped, IDECDuped\n",
    "from all_to_all_autoencoder import AllToAllAutoencoder\n",
    "from all_to_cat_autoencoder import AllToCatAutoencoder\n",
    "from cat_to_cat_autoencoder import CatToCatAutoencoder\n",
    "from load_datasets import load_all_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_accuracy(labels_true, labels_pred):\n",
    "    # We need to map the labels to our cluster labels\n",
    "    # This is a linear assignment problem on a bipartite graph\n",
    "    k = max(len(np.unique(labels_true)), len(np.unique(labels_pred)))\n",
    "    cost_matrix = np.zeros((k, k))\n",
    "    for i in range(labels_true.shape[0]):\n",
    "        cost_matrix[labels_true[i], labels_pred[i]] += 1\n",
    "    inverted_cost_matrix = cost_matrix.max() - cost_matrix\n",
    "    row_ind, col_ind = linear_sum_assignment(inverted_cost_matrix)\n",
    "    return cost_matrix[row_ind, col_ind].sum() / labels_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_block(layers: list, activation_fn: torch.nn.Module = nn.LeakyReLU, output_fn: torch.nn.Module = nn.LeakyReLU, \n",
    "                bias: bool = True, batch_norm: bool = False, dropout: float = None):\n",
    "    block_list = []\n",
    "    for i in range(len(layers) - 1):\n",
    "        block_list.append(torch.nn.Linear(layers[i], layers[i + 1], bias=bias))\n",
    "        if batch_norm:\n",
    "            block_list.append(torch.nn.BatchNorm1d(layers[i + 1]))\n",
    "        if dropout is not None:\n",
    "            block_list.append(torch.nn.Dropout(dropout))\n",
    "        if activation_fn is not None:\n",
    "            if (i != len(layers) - 2):\n",
    "                block_list.append(activation_fn())\n",
    "            else:\n",
    "                if output_fn is not None:\n",
    "                    block_list.append(output_fn())\n",
    "    return torch.nn.Sequential(*block_list)\n",
    "\n",
    "def build_autoencoder(input_dim: int, output_dim: int, layer_per_block: int, activation_fn: torch.nn.Module = nn.LeakyReLU, \n",
    "                      output_fn: torch.nn.Module = nn.LeakyReLU, bias: bool = True, batch_norm: bool = False, dropout: float = None):\n",
    "    hidden_dim = min(input_dim//2, output_dim//2)\n",
    "\n",
    "    encoder_layer_list = list(range(input_dim, hidden_dim - 1, min(-1, -round((input_dim - hidden_dim) / layer_per_block))))\n",
    "    encoder_layer_list[-1] = hidden_dim\n",
    "    encoder = build_block(encoder_layer_list, activation_fn, output_fn, bias, batch_norm, dropout)\n",
    "\n",
    "    decoder_layer_list = list(range(hidden_dim, output_dim + 1, max(1, round((output_dim - hidden_dim) / layer_per_block))))\n",
    "    decoder_layer_list[-1] = output_dim\n",
    "    decoder = build_block(decoder_layer_list, activation_fn, output_fn, bias, batch_norm, dropout)\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_all_datasets(max_rows=5000)\n",
    "\n",
    "accuracies = {d.name: {} for d in datasets}\n",
    "nmis = {d.name: {} for d in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone: Input dim: 9; Cat dim: 2; Cont dim: 7\n",
      "Auction Verification: Input dim: 13; Cat dim: 12; Cont dim: 1\n",
      "Bank Marketing: Input dim: 22; Cat dim: 17; Cont dim: 5\n",
      "Breast Cancer: Input dim: 45; Cat dim: 45; Cont dim: 0\n",
      "Census Income: Input dim: 58; Cat dim: 52; Cont dim: 6\n",
      "Credit Approval: Input dim: 28; Cat dim: 22; Cont dim: 6\n",
      "Heart Disease: Input dim: 17; Cat dim: 11; Cont dim: 6\n",
      "Soybean Disease: Input dim: 55; Cat dim: 55; Cont dim: 0\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    print(f\"{d.name}: Input dim: {d.input_dim}; Cat dim: {d.cat_dim}; Cont dim: {d.cont_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Batch Reconstruction loss: 0.124038\n",
      "Epoch 50/100 - Batch Reconstruction loss: 0.106586\n",
      "Epoch 75/100 - Batch Reconstruction loss: 0.125853\n",
      "Epoch 100/100 - Batch Reconstruction loss: 0.182182\n"
     ]
    }
   ],
   "source": [
    "abalone_encoder = nn.Sequential(\n",
    "    nn.Linear(datasets.abalone.input_dim, 6),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(6, 4),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "abalone_decoder = nn.Sequential(\n",
    "    nn.Linear(4, 6),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(6, datasets.abalone.input_dim),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "device = \"cpu\"\n",
    "ae = AllToAllAutoencoder(deepcopy(abalone_encoder), deepcopy(abalone_decoder), datasets.abalone.input_dim, datasets.abalone.cat_dim, datasets.abalone.embedding_sizes, device=device)\n",
    "ae.fit(datasets.abalone.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "cat = torch.tensor(datasets.abalone.df[datasets.abalone.cat_cols].values, dtype=torch.int).detach().to(device)\n",
    "cont = torch.tensor(datasets.abalone.df[datasets.abalone.cont_cols].values, dtype=torch.float).detach().to(device)\n",
    "features = ae.encode(cat, cont).detach().cpu().numpy()\n",
    "kmeans = KMeans(n_clusters=datasets.abalone.n_targets, init=\"random\", n_init=10, max_iter=300, random_state=0, algorithm=\"lloyd\").fit(features)\n",
    "\n",
    "nmis[datasets.abalone.name][\"All cols AE\"] = normalized_mutual_info_score(datasets.abalone.y, kmeans.labels_)\n",
    "accuracies[datasets.abalone.name][\"All cols AE\"] = cluster_accuracy(datasets.abalone.y, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Batch Reconstruction loss: 0.397039\n",
      "Epoch 50/100 - Batch Reconstruction loss: 0.392506\n",
      "Epoch 75/100 - Batch Reconstruction loss: 0.028997\n",
      "Epoch 100/100 - Batch Reconstruction loss: 0.020927\n"
     ]
    }
   ],
   "source": [
    "abalone_cat_encoder = nn.Sequential(\n",
    "    nn.Linear(datasets.abalone.cat_dim, 2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(2, 1),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "abalone_cat_decoder = nn.Sequential(\n",
    "    nn.Linear(1, 2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(2, datasets.abalone.cat_dim),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "device = \"cpu\"\n",
    "ae = CatToCatAutoencoder(deepcopy(abalone_cat_encoder), deepcopy(abalone_cat_decoder), datasets.abalone.input_dim, datasets.abalone.cat_dim, datasets.abalone.embedding_sizes, device=device)\n",
    "ae.fit(datasets.abalone.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "cat = torch.tensor(datasets.abalone.df[datasets.abalone.cat_cols].values, dtype=torch.int).detach().to(device)\n",
    "cont = datasets.abalone.df[datasets.abalone.cont_cols].values\n",
    "features = np.concatenate((ae.encode(cat, cont).detach().cpu().numpy(), cont), axis=1)\n",
    "kmeans = KMeans(n_clusters=datasets.abalone.n_targets, init=\"random\", n_init=10, max_iter=300, random_state=0, algorithm=\"lloyd\").fit(features)\n",
    "\n",
    "nmis[datasets.abalone.name][\"Cat Cols AE\"] = normalized_mutual_info_score(datasets.abalone.y, kmeans.labels_)\n",
    "accuracies[datasets.abalone.name][\"Cat Cols AE\"] = cluster_accuracy(datasets.abalone.y, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 - Batch Reconstruction loss: 0.037933\n",
      "Epoch 50/100 - Batch Reconstruction loss: 0.023870\n",
      "Epoch 75/100 - Batch Reconstruction loss: 0.004308\n",
      "Epoch 100/100 - Batch Reconstruction loss: 0.001753\n"
     ]
    }
   ],
   "source": [
    "abalone_all_to_cat_encoder = nn.Sequential(\n",
    "    nn.Linear(datasets.abalone.input_dim, 6),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(6, 3),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(3, 1),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "abalone_all_to_cat_decoder = nn.Sequential(\n",
    "    nn.Linear(1, 2),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(2, datasets.abalone.cat_dim),\n",
    "    nn.LeakyReLU(),\n",
    ")\n",
    "\n",
    "\n",
    "device = \"cpu\"\n",
    "ae = AllToCatAutoencoder(deepcopy(abalone_all_to_cat_encoder), deepcopy(abalone_all_to_cat_decoder), datasets.abalone.input_dim, datasets.abalone.cat_dim, datasets.abalone.embedding_sizes, device=device)\n",
    "ae.fit(datasets.abalone.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "cat = torch.tensor(datasets.abalone.df[datasets.abalone.cat_cols].values, dtype=torch.int).detach().to(device)\n",
    "cont = torch.tensor(datasets.abalone.df[datasets.abalone.cont_cols].values, dtype=torch.float).detach().to(device)\n",
    "features = np.concatenate((ae.encode(cat, cont).detach().cpu().numpy(), cont.cpu().numpy()), axis=1)\n",
    "kmeans = KMeans(n_clusters=datasets.abalone.n_targets, init=\"random\", n_init=10, max_iter=300, random_state=0, algorithm=\"lloyd\").fit(features)\n",
    "\n",
    "nmis[datasets.abalone.name][\"All cols to cat cols AE\"] = normalized_mutual_info_score(datasets.abalone.y, kmeans.labels_)\n",
    "accuracies[datasets.abalone.name][\"All cols to cat cols AE\"] = cluster_accuracy(datasets.abalone.y, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All cols AE</th>\n",
       "      <th>Cat Cols AE</th>\n",
       "      <th>All cols to cat cols AE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abalone</th>\n",
       "      <td>0.159608</td>\n",
       "      <td>0.17491</td>\n",
       "      <td>0.171676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auction Verification</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank Marketing</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breast Cancer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Census Income</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Approval</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soybean Disease</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      All cols AE  Cat Cols AE  All cols to cat cols AE\n",
       "Abalone                  0.159608      0.17491                 0.171676\n",
       "Auction Verification          NaN          NaN                      NaN\n",
       "Bank Marketing                NaN          NaN                      NaN\n",
       "Breast Cancer                 NaN          NaN                      NaN\n",
       "Census Income                 NaN          NaN                      NaN\n",
       "Credit Approval               NaN          NaN                      NaN\n",
       "Heart Disease                 NaN          NaN                      NaN\n",
       "Soybean Disease               NaN          NaN                      NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(nmis.values(), index=nmis.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All cols AE</th>\n",
       "      <th>Cat Cols AE</th>\n",
       "      <th>All cols to cat cols AE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abalone</th>\n",
       "      <td>0.136701</td>\n",
       "      <td>0.152262</td>\n",
       "      <td>0.148671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auction Verification</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bank Marketing</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breast Cancer</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Census Income</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Credit Approval</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soybean Disease</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      All cols AE  Cat Cols AE  All cols to cat cols AE\n",
       "Abalone                  0.136701     0.152262                 0.148671\n",
       "Auction Verification          NaN          NaN                      NaN\n",
       "Bank Marketing                NaN          NaN                      NaN\n",
       "Breast Cancer                 NaN          NaN                      NaN\n",
       "Census Income                 NaN          NaN                      NaN\n",
       "Credit Approval               NaN          NaN                      NaN\n",
       "Heart Disease                 NaN          NaN                      NaN\n",
       "Soybean Disease               NaN          NaN                      NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(accuracies.values(), index=accuracies.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
