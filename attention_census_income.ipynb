{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:30.919959Z",
     "end_time": "2023-06-30T23:35:30.922468Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from gower_duped import gower_matrix as gower_matrix_duped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:30.922468Z",
     "end_time": "2023-06-30T23:35:30.931827Z"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_accuracy(y_pred, y_true):\n",
    "    # We need to map the labels to our cluster labels\n",
    "    # This is a linear assignment problem on a bipartite graph\n",
    "    k = max(len(np.unique(y_pred)), len(np.unique(y_pred)))\n",
    "    cost_matrix = np.zeros((k, k))\n",
    "    for i in range(y_pred.size):\n",
    "        cost_matrix[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix.max() - cost_matrix)\n",
    "    return cost_matrix[row_ind, col_ind].sum() / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:30.928324Z",
     "end_time": "2023-06-30T23:35:31.027069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       age          workclass  fnlwgt   education  education-num   \n0       39          State-gov   77516   Bachelors             13  \\\n1       50   Self-emp-not-inc   83311   Bachelors             13   \n2       38            Private  215646     HS-grad              9   \n3       53            Private  234721        11th              7   \n4       28            Private  338409   Bachelors             13   \n...    ...                ...     ...         ...            ...   \n48837   39            Private  215419   Bachelors             13   \n48838   64                  ?  321403     HS-grad              9   \n48839   38            Private  374983   Bachelors             13   \n48840   44            Private   83891   Bachelors             13   \n48841   35       Self-emp-inc  182148   Bachelors             13   \n\n            marital-status          occupation     relationship   \n0            Never-married        Adm-clerical    Not-in-family  \\\n1       Married-civ-spouse     Exec-managerial          Husband   \n2                 Divorced   Handlers-cleaners    Not-in-family   \n3       Married-civ-spouse   Handlers-cleaners          Husband   \n4       Married-civ-spouse      Prof-specialty             Wife   \n...                    ...                 ...              ...   \n48837             Divorced      Prof-specialty    Not-in-family   \n48838              Widowed                   ?   Other-relative   \n48839   Married-civ-spouse      Prof-specialty          Husband   \n48840             Divorced        Adm-clerical        Own-child   \n48841   Married-civ-spouse     Exec-managerial          Husband   \n\n                      race      sex  capital-gain  capital-loss   \n0                    White     Male          2174             0  \\\n1                    White     Male             0             0   \n2                    White     Male             0             0   \n3                    Black     Male             0             0   \n4                    Black   Female             0             0   \n...                    ...      ...           ...           ...   \n48837                White   Female             0             0   \n48838                Black     Male             0             0   \n48839                White     Male             0             0   \n48840   Asian-Pac-Islander     Male          5455             0   \n48841                White     Male             0             0   \n\n       hours-per-week  native-country    class  \n0                  40   United-States    <=50K  \n1                  13   United-States    <=50K  \n2                  40   United-States    <=50K  \n3                  40   United-States    <=50K  \n4                  40            Cuba    <=50K  \n...               ...             ...      ...  \n48837              36   United-States   <=50K.  \n48838              40   United-States   <=50K.  \n48839              50   United-States   <=50K.  \n48840              40   United-States   <=50K.  \n48841              60   United-States    >50K.  \n\n[48842 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48837</th>\n      <td>39</td>\n      <td>Private</td>\n      <td>215419</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Divorced</td>\n      <td>Prof-specialty</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36</td>\n      <td>United-States</td>\n      <td>&lt;=50K.</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>64</td>\n      <td>?</td>\n      <td>321403</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Widowed</td>\n      <td>?</td>\n      <td>Other-relative</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K.</td>\n    </tr>\n    <tr>\n      <th>48839</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>374983</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>50</td>\n      <td>United-States</td>\n      <td>&lt;=50K.</td>\n    </tr>\n    <tr>\n      <th>48840</th>\n      <td>44</td>\n      <td>Private</td>\n      <td>83891</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Divorced</td>\n      <td>Adm-clerical</td>\n      <td>Own-child</td>\n      <td>Asian-Pac-Islander</td>\n      <td>Male</td>\n      <td>5455</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K.</td>\n    </tr>\n    <tr>\n      <th>48841</th>\n      <td>35</td>\n      <td>Self-emp-inc</td>\n      <td>182148</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>United-States</td>\n      <td>&gt;50K.</td>\n    </tr>\n  </tbody>\n</table>\n<p>48842 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(\"datasets/census_income.csv\")\n",
    "og_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7607182343065395"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df.loc[(og_df[\"class\"] == \" <=50K.\") | (og_df[\"class\"] == \" <=50K\"), \"class\"] = 0\n",
    "og_df.loc[(og_df[\"class\"] == \" >50K.\") | (og_df[\"class\"] == \" >50K\"), \"class\"] = 1\n",
    "# Probability of most common class\n",
    "og_df[\"class\"].value_counts().max()/og_df[\"class\"].count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.025070Z",
     "end_time": "2023-06-30T23:35:31.065800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.054766Z",
     "end_time": "2023-06-30T23:35:31.097877Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = [\"workclass\", \"education\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "cont_cols = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.057282Z",
     "end_time": "2023-06-30T23:35:31.160102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            age  workclass    fnlwgt  education  education-num   \n0      0.301370          7  0.044131          9       0.800000  \\\n1      0.452055          6  0.048052          9       0.800000   \n2      0.287671          4  0.137581         11       0.533333   \n3      0.493151          4  0.150486          1       0.400000   \n4      0.150685          4  0.220635          9       0.800000   \n...         ...        ...       ...        ...            ...   \n48837  0.301370          4  0.137428          9       0.800000   \n48838  0.643836          0  0.209130         11       0.533333   \n48839  0.287671          4  0.245379          9       0.800000   \n48840  0.369863          4  0.048444          9       0.800000   \n48841  0.246575          5  0.114919          9       0.800000   \n\n       marital-status  occupation  relationship  race  sex  capital-gain   \n0                   4           1             1     4    1      0.021740  \\\n1                   2           4             0     4    1      0.000000   \n2                   0           6             1     4    1      0.000000   \n3                   2           6             0     2    1      0.000000   \n4                   2          10             5     2    0      0.000000   \n...               ...         ...           ...   ...  ...           ...   \n48837               0          10             1     4    0      0.000000   \n48838               6           0             2     2    1      0.000000   \n48839               2          10             0     4    1      0.000000   \n48840               0           1             3     1    1      0.054551   \n48841               2           4             0     4    1      0.000000   \n\n       capital-loss  hours-per-week  native-country  \n0               0.0        0.397959              39  \n1               0.0        0.122449              39  \n2               0.0        0.397959              39  \n3               0.0        0.397959              39  \n4               0.0        0.397959               5  \n...             ...             ...             ...  \n48837           0.0        0.357143              39  \n48838           0.0        0.397959              39  \n48839           0.0        0.500000              39  \n48840           0.0        0.397959              39  \n48841           0.0        0.602041              39  \n\n[48842 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education-num</th>\n      <th>marital-status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>native-country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.301370</td>\n      <td>7</td>\n      <td>0.044131</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.021740</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.452055</td>\n      <td>6</td>\n      <td>0.048052</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.122449</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.287671</td>\n      <td>4</td>\n      <td>0.137581</td>\n      <td>11</td>\n      <td>0.533333</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.493151</td>\n      <td>4</td>\n      <td>0.150486</td>\n      <td>1</td>\n      <td>0.400000</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.150685</td>\n      <td>4</td>\n      <td>0.220635</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>2</td>\n      <td>10</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48837</th>\n      <td>0.301370</td>\n      <td>4</td>\n      <td>0.137428</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>0</td>\n      <td>10</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.357143</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>0.643836</td>\n      <td>0</td>\n      <td>0.209130</td>\n      <td>11</td>\n      <td>0.533333</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>48839</th>\n      <td>0.287671</td>\n      <td>4</td>\n      <td>0.245379</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>48840</th>\n      <td>0.369863</td>\n      <td>4</td>\n      <td>0.048444</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.054551</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>48841</th>\n      <td>0.246575</td>\n      <td>5</td>\n      <td>0.114919</td>\n      <td>9</td>\n      <td>0.800000</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.602041</td>\n      <td>39</td>\n    </tr>\n  </tbody>\n</table>\n<p>48842 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = og_df.copy()\n",
    "df.drop(columns=\"class\", inplace=True)\n",
    "df[cat_cols] = df[cat_cols].apply(LabelEncoder().fit_transform)\n",
    "df[cont_cols] = MinMaxScaler().fit_transform(df[cont_cols])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.131650Z",
     "end_time": "2023-06-30T23:35:31.345752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            age    fnlwgt  education-num  capital-gain  capital-loss   \n0      0.301370  0.044131       0.800000      0.021740           0.0  \\\n1      0.452055  0.048052       0.800000      0.000000           0.0   \n2      0.287671  0.137581       0.533333      0.000000           0.0   \n3      0.493151  0.150486       0.400000      0.000000           0.0   \n4      0.150685  0.220635       0.800000      0.000000           0.0   \n...         ...       ...            ...           ...           ...   \n48837  0.301370  0.137428       0.800000      0.000000           0.0   \n48838  0.643836  0.209130       0.533333      0.000000           0.0   \n48839  0.287671  0.245379       0.800000      0.000000           0.0   \n48840  0.369863  0.048444       0.800000      0.054551           0.0   \n48841  0.246575  0.114919       0.800000      0.000000           0.0   \n\n       hours-per-week  workclass_ ?  workclass_ Federal-gov   \n0            0.397959           0.0                     0.0  \\\n1            0.122449           0.0                     0.0   \n2            0.397959           0.0                     0.0   \n3            0.397959           0.0                     0.0   \n4            0.397959           0.0                     0.0   \n...               ...           ...                     ...   \n48837        0.357143           0.0                     0.0   \n48838        0.397959           1.0                     0.0   \n48839        0.500000           0.0                     0.0   \n48840        0.397959           0.0                     0.0   \n48841        0.602041           0.0                     0.0   \n\n       workclass_ Local-gov  workclass_ Never-worked  ...   \n0                       0.0                      0.0  ...  \\\n1                       0.0                      0.0  ...   \n2                       0.0                      0.0  ...   \n3                       0.0                      0.0  ...   \n4                       0.0                      0.0  ...   \n...                     ...                      ...  ...   \n48837                   0.0                      0.0  ...   \n48838                   0.0                      0.0  ...   \n48839                   0.0                      0.0  ...   \n48840                   0.0                      0.0  ...   \n48841                   0.0                      0.0  ...   \n\n       native-country_ Portugal  native-country_ Puerto-Rico   \n0                           0.0                          0.0  \\\n1                           0.0                          0.0   \n2                           0.0                          0.0   \n3                           0.0                          0.0   \n4                           0.0                          0.0   \n...                         ...                          ...   \n48837                       0.0                          0.0   \n48838                       0.0                          0.0   \n48839                       0.0                          0.0   \n48840                       0.0                          0.0   \n48841                       0.0                          0.0   \n\n       native-country_ Scotland  native-country_ South   \n0                           0.0                    0.0  \\\n1                           0.0                    0.0   \n2                           0.0                    0.0   \n3                           0.0                    0.0   \n4                           0.0                    0.0   \n...                         ...                    ...   \n48837                       0.0                    0.0   \n48838                       0.0                    0.0   \n48839                       0.0                    0.0   \n48840                       0.0                    0.0   \n48841                       0.0                    0.0   \n\n       native-country_ Taiwan  native-country_ Thailand   \n0                         0.0                       0.0  \\\n1                         0.0                       0.0   \n2                         0.0                       0.0   \n3                         0.0                       0.0   \n4                         0.0                       0.0   \n...                       ...                       ...   \n48837                     0.0                       0.0   \n48838                     0.0                       0.0   \n48839                     0.0                       0.0   \n48840                     0.0                       0.0   \n48841                     0.0                       0.0   \n\n       native-country_ Trinadad&Tobago  native-country_ United-States   \n0                                  0.0                            1.0  \\\n1                                  0.0                            1.0   \n2                                  0.0                            1.0   \n3                                  0.0                            1.0   \n4                                  0.0                            0.0   \n...                                ...                            ...   \n48837                              0.0                            1.0   \n48838                              0.0                            1.0   \n48839                              0.0                            1.0   \n48840                              0.0                            1.0   \n48841                              0.0                            1.0   \n\n       native-country_ Vietnam  native-country_ Yugoslavia  \n0                          0.0                         0.0  \n1                          0.0                         0.0  \n2                          0.0                         0.0  \n3                          0.0                         0.0  \n4                          0.0                         0.0  \n...                        ...                         ...  \n48837                      0.0                         0.0  \n48838                      0.0                         0.0  \n48839                      0.0                         0.0  \n48840                      0.0                         0.0  \n48841                      0.0                         0.0  \n\n[48842 rows x 108 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fnlwgt</th>\n      <th>education-num</th>\n      <th>capital-gain</th>\n      <th>capital-loss</th>\n      <th>hours-per-week</th>\n      <th>workclass_ ?</th>\n      <th>workclass_ Federal-gov</th>\n      <th>workclass_ Local-gov</th>\n      <th>workclass_ Never-worked</th>\n      <th>...</th>\n      <th>native-country_ Portugal</th>\n      <th>native-country_ Puerto-Rico</th>\n      <th>native-country_ Scotland</th>\n      <th>native-country_ South</th>\n      <th>native-country_ Taiwan</th>\n      <th>native-country_ Thailand</th>\n      <th>native-country_ Trinadad&amp;Tobago</th>\n      <th>native-country_ United-States</th>\n      <th>native-country_ Vietnam</th>\n      <th>native-country_ Yugoslavia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.301370</td>\n      <td>0.044131</td>\n      <td>0.800000</td>\n      <td>0.021740</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.452055</td>\n      <td>0.048052</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.122449</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.287671</td>\n      <td>0.137581</td>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.493151</td>\n      <td>0.150486</td>\n      <td>0.400000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.150685</td>\n      <td>0.220635</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48837</th>\n      <td>0.301370</td>\n      <td>0.137428</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.357143</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>48838</th>\n      <td>0.643836</td>\n      <td>0.209130</td>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>48839</th>\n      <td>0.287671</td>\n      <td>0.245379</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>48840</th>\n      <td>0.369863</td>\n      <td>0.048444</td>\n      <td>0.800000</td>\n      <td>0.054551</td>\n      <td>0.0</td>\n      <td>0.397959</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>48841</th>\n      <td>0.246575</td>\n      <td>0.114919</td>\n      <td>0.800000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.602041</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>48842 rows × 108 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_feature(df, feature_to_encode):\n",
    "    dummies = pd.get_dummies(df[[feature_to_encode]], dtype=float)\n",
    "    result_df = pd.concat([df, dummies], axis=1)\n",
    "    result_df.drop(columns=feature_to_encode, inplace=True)\n",
    "    return result_df\n",
    "\n",
    "df_one_hot = og_df.copy()\n",
    "df_one_hot.drop(columns=\"class\", inplace=True)\n",
    "df_one_hot[cont_cols] = MinMaxScaler().fit_transform(df_one_hot[cont_cols])\n",
    "for col in cat_cols:\n",
    "    df_one_hot = encode_feature(df_one_hot, col)\n",
    "df_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7165758977928832"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=\"auto\", random_state=0).fit(df_one_hot)\n",
    "kmeans_acc = cluster_accuracy(kmeans.labels_, og_df[\"class\"].to_numpy())\n",
    "kmeans_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.343751Z",
     "end_time": "2023-06-30T23:35:31.476627Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1325918200579342"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_nmi = normalized_mutual_info_score(og_df[\"class\"].to_numpy(), kmeans.labels_)\n",
    "kmeans_nmi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.466111Z",
     "end_time": "2023-06-30T23:35:31.547249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48842/48842 [18:37<00:00, 43.69it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.        , 0.3179897 , 0.31396827, ..., 0.30990908, 0.2932583 ,\n        0.31081456],\n       [0.3179897 , 0.        , 0.41400644, ..., 0.19566154, 0.38661748,\n        0.12513845],\n       [0.31396827, 0.41400644, 0.        , ..., 0.31975034, 0.32089615,\n        0.3953219 ],\n       ...,\n       [0.30990908, 0.19566154, 0.31975034, ..., 0.        , 0.31683698,\n        0.16239977],\n       [0.2932583 , 0.38661748, 0.32089615, ..., 0.31683698, 0.        ,\n        0.38917103],\n       [0.31081456, 0.12513845, 0.3953219 , ..., 0.16239977, 0.38917103,\n        0.        ]], dtype=float32)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_target_df = og_df.drop(columns=\"class\")\n",
    "distance_matrix = gower_matrix_duped(no_target_df)\n",
    "distance_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-30T23:35:31.516701Z",
     "end_time": "2023-06-30T23:54:09.483416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7602882764833545"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gower_agglo = AgglomerativeClustering(n_clusters=2, metric=\"precomputed\", linkage=\"average\").fit_predict(distance_matrix)\n",
    "gower_agglo_acc = cluster_accuracy(gower_agglo, og_df[\"class\"].to_numpy())\n",
    "gower_agglo_acc\n",
    "# linkage=average: 0.7602882764833545\n",
    "# linkage=single: 0.760697760124483"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-30T23:54:09.483416Z",
     "end_time": "2023-06-30T23:58:55.757825Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "2.3468560869329926e-05"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gower_agglo_nmi = normalized_mutual_info_score(og_df[\"class\"].to_numpy(), gower_agglo)\n",
    "gower_agglo_nmi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-30T23:58:55.751833Z",
     "end_time": "2023-06-30T23:58:56.559387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:58:55.957674Z",
     "end_time": "2023-06-30T23:58:56.583384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(9, 5), (16, 8), (7, 4), (15, 8), (6, 3), (5, 3), (2, 2), (42, 21)]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(df[col].nunique(), min(50, max(2, (df[col].nunique()+1) // 2))) for col in df[cat_cols]]\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:58:56.192191Z",
     "end_time": "2023-06-30T23:58:56.699901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "48842"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CensusIncomeDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.cat = torch.tensor(df[cat_cols].values, dtype=torch.float)\n",
    "        self.cont = torch.tensor(df[cont_cols].values, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cat[idx], self.cont[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cat.shape[0]\n",
    "    \n",
    "dataset = CensusIncomeDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-30T23:58:56.734633Z",
     "end_time": "2023-07-01T00:00:18.757053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 1.081454\n",
      "epoch: 2/100, loss = 0.810576\n",
      "epoch: 3/100, loss = 0.782044\n",
      "epoch: 4/100, loss = 0.759625\n",
      "epoch: 5/100, loss = 0.736315\n",
      "epoch: 6/100, loss = 0.717795\n",
      "epoch: 7/100, loss = 0.697768\n",
      "epoch: 8/100, loss = 0.680314\n",
      "epoch: 9/100, loss = 0.666005\n",
      "epoch: 10/100, loss = 0.653759\n",
      "epoch: 11/100, loss = 0.644495\n",
      "epoch: 12/100, loss = 0.635795\n",
      "epoch: 13/100, loss = 0.626431\n",
      "epoch: 14/100, loss = 0.619718\n",
      "epoch: 15/100, loss = 0.612891\n",
      "epoch: 16/100, loss = 0.605771\n",
      "epoch: 17/100, loss = 0.599854\n",
      "epoch: 18/100, loss = 0.593850\n",
      "epoch: 19/100, loss = 0.588277\n",
      "epoch: 20/100, loss = 0.582965\n",
      "epoch: 21/100, loss = 0.578347\n",
      "epoch: 22/100, loss = 0.574253\n",
      "epoch: 23/100, loss = 0.570368\n",
      "epoch: 24/100, loss = 0.567287\n",
      "epoch: 25/100, loss = 0.565001\n",
      "epoch: 26/100, loss = 0.562682\n",
      "epoch: 27/100, loss = 0.560616\n",
      "epoch: 28/100, loss = 0.558432\n",
      "epoch: 29/100, loss = 0.557205\n",
      "epoch: 30/100, loss = 0.556095\n",
      "epoch: 31/100, loss = 0.555376\n",
      "epoch: 32/100, loss = 0.552496\n",
      "epoch: 33/100, loss = 0.549477\n",
      "epoch: 34/100, loss = 0.546727\n",
      "epoch: 35/100, loss = 0.544217\n",
      "epoch: 36/100, loss = 0.542422\n",
      "epoch: 37/100, loss = 0.540640\n",
      "epoch: 38/100, loss = 0.539094\n",
      "epoch: 39/100, loss = 0.538280\n",
      "epoch: 40/100, loss = 0.537032\n",
      "epoch: 41/100, loss = 0.536267\n",
      "epoch: 42/100, loss = 0.535720\n",
      "epoch: 43/100, loss = 0.535497\n",
      "epoch: 44/100, loss = 0.535738\n",
      "epoch: 45/100, loss = 0.535206\n",
      "epoch: 46/100, loss = 0.535186\n",
      "epoch: 47/100, loss = 0.535174\n",
      "epoch: 48/100, loss = 0.534748\n",
      "epoch: 49/100, loss = 0.534735\n",
      "epoch: 50/100, loss = 0.534526\n",
      "epoch: 51/100, loss = 0.533915\n",
      "epoch: 52/100, loss = 0.533982\n",
      "epoch: 53/100, loss = 0.533910\n",
      "epoch: 54/100, loss = 0.533711\n",
      "epoch: 55/100, loss = 0.533645\n",
      "epoch: 56/100, loss = 0.533303\n",
      "epoch: 57/100, loss = 0.533347\n",
      "epoch: 58/100, loss = 0.533398\n",
      "epoch: 59/100, loss = 0.533803\n",
      "epoch: 60/100, loss = 0.534283\n",
      "epoch: 61/100, loss = 0.535534\n",
      "epoch: 62/100, loss = 0.536299\n",
      "epoch: 63/100, loss = 0.536951\n",
      "epoch: 64/100, loss = 0.538057\n",
      "epoch: 65/100, loss = 0.539323\n",
      "epoch: 66/100, loss = 0.541292\n",
      "epoch: 67/100, loss = 0.542475\n",
      "epoch: 68/100, loss = 0.544874\n",
      "epoch: 69/100, loss = 0.547389\n",
      "epoch: 70/100, loss = 0.549279\n",
      "epoch: 71/100, loss = 0.550433\n",
      "epoch: 72/100, loss = 0.551613\n",
      "epoch: 73/100, loss = 0.551866\n",
      "epoch: 74/100, loss = 0.552180\n",
      "epoch: 75/100, loss = 0.552364\n",
      "epoch: 76/100, loss = 0.552816\n",
      "epoch: 77/100, loss = 0.553621\n",
      "epoch: 78/100, loss = 0.554403\n",
      "epoch: 79/100, loss = 0.553852\n",
      "epoch: 80/100, loss = 0.553447\n",
      "epoch: 81/100, loss = 0.554263\n",
      "epoch: 82/100, loss = 0.555205\n",
      "epoch: 83/100, loss = 0.554976\n",
      "epoch: 84/100, loss = 0.555061\n",
      "epoch: 85/100, loss = 0.554996\n",
      "epoch: 86/100, loss = 0.555977\n",
      "epoch: 87/100, loss = 0.556167\n",
      "epoch: 88/100, loss = 0.556149\n",
      "epoch: 89/100, loss = 0.556219\n",
      "epoch: 90/100, loss = 0.556357\n",
      "epoch: 91/100, loss = 0.556193\n",
      "epoch: 92/100, loss = 0.556514\n",
      "epoch: 93/100, loss = 0.556308\n",
      "epoch: 94/100, loss = 0.556568\n",
      "epoch: 95/100, loss = 0.556430\n",
      "epoch: 96/100, loss = 0.557059\n",
      "epoch: 97/100, loss = 0.557560\n",
      "epoch: 98/100, loss = 0.557681\n",
      "epoch: 99/100, loss = 0.557851\n",
      "epoch: 100/100, loss = 0.559013\n"
     ]
    }
   ],
   "source": [
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num, dim) for num, dim in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        in_dim = n_emb + len(cont_cols)\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_dim, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.Linear(32, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(16),\n",
    "            torch.nn.Linear(16, 8),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(8, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, in_dim),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def encode(self, x_cat, x_cont):\n",
    "        x_cat = x_cat.to(torch.long)\n",
    "        embedded = torch.cat([e(x_cat[:, i]) for i, e in enumerate(self.embeddings)], 1)\n",
    "        self.last_target = embedded.clone().detach()\n",
    "\n",
    "        qkv = torch.cat((embedded, x_cont), 1)\n",
    "        x = F.scaled_dot_product_attention(qkv, qkv, qkv)\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        encoded = self.encode(x_cat, x_cont)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "model = AttentionModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for x_cat, x_cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_cat, x_cont)\n",
    "        train_loss = criterion(outputs, torch.cat((model.last_target, x_cont), 1))\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.7731142 ,  2.2105112 ,  2.4065523 , ..., -0.95765257,\n         2.0670462 ,  1.998209  ],\n       [-2.1812267 ,  2.2791386 ,  1.3138523 , ...,  1.6385336 ,\n        -1.7250853 ,  0.4066143 ],\n       [-0.47664738, -0.61287594, -1.8925271 , ...,  1.7260189 ,\n        -1.6755476 , -2.3692465 ],\n       ...,\n       [-2.214448  ,  1.5419874 ,  0.33006716, ...,  2.3086662 ,\n        -2.3054028 ,  0.78027916],\n       [-1.505003  ,  2.1899023 ,  1.892911  , ...,  2.6764307 ,\n        -0.8353691 ,  1.4537773 ],\n       [-2.2850761 ,  2.9549255 ,  1.9880047 , ...,  0.5408449 ,\n        -1.1282539 , -0.2725029 ]], dtype=float32)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = torch.tensor(df[cat_cols].values, dtype=torch.float)\n",
    "cont = torch.tensor(df[cont_cols].values, dtype=torch.float)\n",
    "features = model.encode(cat, cont).detach().numpy()\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-01T00:00:18.758052Z",
     "end_time": "2023-07-01T00:00:27.073022Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6074689816141845"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, n_init=\"auto\", random_state=0).fit(features)\n",
    "deep_acc = cluster_accuracy(kmeans.labels_, og_df[\"class\"].to_numpy())\n",
    "deep_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-01T00:00:27.074023Z",
     "end_time": "2023-07-01T00:00:27.169158Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "0.12904984832427263"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_nmi = normalized_mutual_info_score(og_df[\"class\"].to_numpy(), kmeans.labels_)\n",
    "deep_nmi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-01T00:00:27.171158Z",
     "end_time": "2023-07-01T00:00:27.221163Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "                       Accuracy       NMI\nKMeans                 0.716576  0.132592\nGower + Agglomerative  0.760288  0.000023\nDeep Attention KMeans  0.607469  0.129050",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accuracy</th>\n      <th>NMI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>KMeans</th>\n      <td>0.716576</td>\n      <td>0.132592</td>\n    </tr>\n    <tr>\n      <th>Gower + Agglomerative</th>\n      <td>0.760288</td>\n      <td>0.000023</td>\n    </tr>\n    <tr>\n      <th>Deep Attention KMeans</th>\n      <td>0.607469</td>\n      <td>0.129050</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[kmeans_acc, kmeans_nmi], [gower_agglo_acc, gower_agglo_nmi], [deep_acc, deep_nmi]], index=[\"KMeans\", \"Gower + Agglomerative\", \"Deep Attention KMeans\"], columns=[\"Accuracy\", \"NMI\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-01T00:04:50.235694Z",
     "end_time": "2023-07-01T00:04:50.239212Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
