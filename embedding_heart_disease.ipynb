{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.183611Z",
     "end_time": "2023-06-25T22:36:33.192173Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.187134Z",
     "end_time": "2023-06-25T22:36:33.197644Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_accuracy(y_pred, y_true):\n",
    "    # We need to map the labels to our cluster labels\n",
    "    # This is a linear assignment problem on a bipartite graph\n",
    "    k = max(len(np.unique(y_pred)), len(np.unique(y_pred)))\n",
    "    cost_matrix = np.zeros((k, k))\n",
    "    for i in range(y_pred.size):\n",
    "        cost_matrix[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix.max() - cost_matrix)\n",
    "    return cost_matrix[row_ind, col_ind].sum() / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.198645Z",
     "end_time": "2023-06-25T22:36:33.224180Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     age     sex               cp  trestbps   chol    fbs           restecg   \n0     63    Male   typical angina     145.0  233.0   True    lv hypertrophy  \\\n1     67    Male     asymptomatic     160.0  286.0  False    lv hypertrophy   \n2     67    Male     asymptomatic     120.0  229.0  False    lv hypertrophy   \n5     56    Male  atypical angina     120.0  236.0  False            normal   \n6     62  Female     asymptomatic     140.0  268.0  False    lv hypertrophy   \n..   ...     ...              ...       ...    ...    ...               ...   \n913   62    Male     asymptomatic     158.0  170.0  False  st-t abnormality   \n914   46    Male     asymptomatic     134.0  310.0  False            normal   \n915   54  Female     asymptomatic     127.0  333.0   True  st-t abnormality   \n917   55    Male     asymptomatic     122.0  223.0   True  st-t abnormality   \n919   62    Male  atypical angina     120.0  254.0  False    lv hypertrophy   \n\n     thalch  exang  oldpeak        slope   ca               thal  num  \n0     150.0  False      2.3  downsloping  0.0       fixed defect    0  \n1     108.0   True      1.5         flat  3.0             normal    2  \n2     129.0   True      2.6         flat  2.0  reversable defect    1  \n5     178.0  False      0.8    upsloping  0.0             normal    0  \n6     160.0  False      3.6  downsloping  2.0             normal    3  \n..      ...    ...      ...          ...  ...                ...  ...  \n913   138.0   True      0.0          NaN  NaN                NaN    1  \n914   126.0  False      0.0          NaN  NaN             normal    2  \n915   154.0  False      0.0          NaN  NaN                NaN    1  \n917   100.0  False      0.0          NaN  NaN       fixed defect    2  \n919    93.0   True      0.0          NaN  NaN                NaN    1  \n\n[797 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>Male</td>\n      <td>typical angina</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>True</td>\n      <td>lv hypertrophy</td>\n      <td>150.0</td>\n      <td>False</td>\n      <td>2.3</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>fixed defect</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>108.0</td>\n      <td>True</td>\n      <td>1.5</td>\n      <td>flat</td>\n      <td>3.0</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>129.0</td>\n      <td>True</td>\n      <td>2.6</td>\n      <td>flat</td>\n      <td>2.0</td>\n      <td>reversable defect</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>236.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>178.0</td>\n      <td>False</td>\n      <td>0.8</td>\n      <td>upsloping</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62</td>\n      <td>Female</td>\n      <td>asymptomatic</td>\n      <td>140.0</td>\n      <td>268.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>160.0</td>\n      <td>False</td>\n      <td>3.6</td>\n      <td>downsloping</td>\n      <td>2.0</td>\n      <td>normal</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>158.0</td>\n      <td>170.0</td>\n      <td>False</td>\n      <td>st-t abnormality</td>\n      <td>138.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>46</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>134.0</td>\n      <td>310.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>126.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>Female</td>\n      <td>asymptomatic</td>\n      <td>127.0</td>\n      <td>333.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>154.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>122.0</td>\n      <td>223.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>100.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>fixed defect</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>254.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>93.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(\"datasets/heart_disease_uci.csv\")\n",
    "og_df.drop(columns=[\"id\", \"dataset\"], inplace=True)\n",
    "og_df = og_df.drop(og_df[og_df[\"num\"] == 0].sample(frac=0.3).index)\n",
    "og_df # this df still has \"num\" -> the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.219666Z",
     "end_time": "2023-06-25T22:36:33.224180Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorial_columns = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\"]\n",
    "cont_columns = [\"age\", \"trestbps\", \"chol\", \"thalch\", \"oldpeak\", \"ca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.222180Z",
     "end_time": "2023-06-25T22:36:33.246498Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          age  sex        cp  trestbps      chol  fbs   restecg    thalch   \n0    0.714286  1.0  1.000000     0.725  0.386401  0.5  0.000000  0.633803  \\\n1    0.795918  1.0  0.000000     0.800  0.474295  0.0  0.000000  0.338028   \n2    0.795918  1.0  0.000000     0.600  0.379768  0.0  0.000000  0.485915   \n5    0.571429  1.0  0.333333     0.600  0.391376  0.0  0.333333  0.830986   \n6    0.693878  0.0  0.000000     0.700  0.444444  0.0  0.000000  0.704225   \n..        ...  ...       ...       ...       ...  ...       ...       ...   \n913  0.693878  1.0  0.000000     0.790  0.281924  0.0  0.666667  0.549296   \n914  0.367347  1.0  0.000000     0.670  0.514096  0.0  0.333333  0.464789   \n915  0.530612  0.0  0.000000     0.635  0.552239  0.5  0.666667  0.661972   \n917  0.551020  1.0  0.000000     0.610  0.369818  0.5  0.666667  0.281690   \n919  0.693878  1.0  0.333333     0.600  0.421227  0.0  0.000000  0.232394   \n\n     exang   oldpeak     slope        ca      thal  \n0      0.0  0.556818  0.000000  0.000000  0.000000  \n1      0.5  0.465909  0.333333  1.000000  0.333333  \n2      0.5  0.590909  0.333333  0.666667  0.666667  \n5      0.0  0.386364  0.666667  0.000000  0.333333  \n6      0.0  0.704545  0.000000  0.666667  0.333333  \n..     ...       ...       ...       ...       ...  \n913    0.5  0.295455  1.000000  0.247765  1.000000  \n914    0.0  0.295455  1.000000  0.247765  0.333333  \n915    0.0  0.295455  1.000000  0.247765  1.000000  \n917    0.0  0.295455  1.000000  0.247765  0.000000  \n919    0.5  0.295455  1.000000  0.247765  1.000000  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.714286</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.725</td>\n      <td>0.386401</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.633803</td>\n      <td>0.0</td>\n      <td>0.556818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.800</td>\n      <td>0.474295</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.338028</td>\n      <td>0.5</td>\n      <td>0.465909</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.600</td>\n      <td>0.379768</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.485915</td>\n      <td>0.5</td>\n      <td>0.590909</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.571429</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600</td>\n      <td>0.391376</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.830986</td>\n      <td>0.0</td>\n      <td>0.386364</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.693878</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.700</td>\n      <td>0.444444</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.704225</td>\n      <td>0.0</td>\n      <td>0.704545</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.790</td>\n      <td>0.281924</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.549296</td>\n      <td>0.5</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.247765</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>0.367347</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.670</td>\n      <td>0.514096</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.464789</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.247765</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0.530612</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.635</td>\n      <td>0.552239</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.661972</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.247765</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>0.551020</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.610</td>\n      <td>0.369818</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.281690</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.247765</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600</td>\n      <td>0.421227</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.232394</td>\n      <td>0.5</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.247765</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_max = og_df.copy()\n",
    "df_min_max.drop(columns=\"num\", inplace=True)\n",
    "df_min_max[categorial_columns] = df_min_max[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df_min_max[categorial_columns] = MinMaxScaler().fit_transform(df_min_max[categorial_columns])\n",
    "df_min_max[cont_columns] = MinMaxScaler().fit_transform(df_min_max[cont_columns])\n",
    "df_min_max = df_min_max.fillna(df_min_max.mean())\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.248497Z",
     "end_time": "2023-06-25T22:36:33.301127Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps   chol  fbs  restecg  thalch  exang  oldpeak   \n0     63    1   3     145.0  233.0    1        0   150.0      0      2.3  \\\n1     67    1   0     160.0  286.0    0        0   108.0      1      1.5   \n2     67    1   0     120.0  229.0    0        0   129.0      1      2.6   \n5     56    1   1     120.0  236.0    0        1   178.0      0      0.8   \n6     62    0   0     140.0  268.0    0        0   160.0      0      3.6   \n..   ...  ...  ..       ...    ...  ...      ...     ...    ...      ...   \n913   62    1   0     158.0  170.0    0        2   138.0      1      0.0   \n914   46    1   0     134.0  310.0    0        1   126.0      0      0.0   \n915   54    0   0     127.0  333.0    1        2   154.0      0      0.0   \n917   55    1   0     122.0  223.0    1        2   100.0      0      0.0   \n919   62    1   1     120.0  254.0    0        0    93.0      1      0.0   \n\n     slope        ca  thal  \n0        0  0.000000     0  \n1        1  3.000000     1  \n2        1  2.000000     2  \n5        2  0.000000     1  \n6        0  2.000000     1  \n..     ...       ...   ...  \n913      3  0.743295     3  \n914      3  0.743295     1  \n915      3  0.743295     3  \n917      3  0.743295     0  \n919      3  0.743295     3  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150.0</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.0</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>3.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>129.0</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>236.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140.0</td>\n      <td>268.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>3.6</td>\n      <td>0</td>\n      <td>2.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>62</td>\n      <td>1</td>\n      <td>0</td>\n      <td>158.0</td>\n      <td>170.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>138.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.743295</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>46</td>\n      <td>1</td>\n      <td>0</td>\n      <td>134.0</td>\n      <td>310.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>126.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.743295</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>0</td>\n      <td>0</td>\n      <td>127.0</td>\n      <td>333.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>154.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.743295</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>122.0</td>\n      <td>223.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.743295</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>254.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.743295</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_min_max = og_df.copy()\n",
    "df_no_min_max.drop(columns=\"num\", inplace=True)\n",
    "df_no_min_max[categorial_columns] = df_no_min_max[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df_no_min_max = df_no_min_max.fillna(df_no_min_max.mean())\n",
    "df_no_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.263809Z",
     "end_time": "2023-06-25T22:36:33.305128Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HeartDiseaseDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.cat = torch.tensor(df[categorial_columns].values, dtype=torch.float)\n",
    "        self.cont = torch.tensor(df[cont_columns].values, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cat[idx], self.cont[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.269250Z",
     "end_time": "2023-06-25T22:36:33.315477Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "797"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = HeartDiseaseDataset(df_min_max)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.282129Z",
     "end_time": "2023-06-25T22:36:33.315477Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(2, 2), (4, 2), (3, 2), (4, 2), (3, 2), (4, 2), (4, 2)]"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(df_no_min_max[col].nunique(), min(50, max(2, (df_no_min_max[col].nunique()+1) // 2))) for col in df_no_min_max[categorial_columns]]\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:33.290400Z",
     "end_time": "2023-06-25T22:36:35.133331Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 1.457249\n",
      "epoch: 2/100, loss = 1.428930\n",
      "epoch: 3/100, loss = 1.406558\n",
      "epoch: 4/100, loss = 1.386416\n",
      "epoch: 5/100, loss = 1.369587\n",
      "epoch: 6/100, loss = 1.352072\n",
      "epoch: 7/100, loss = 1.335533\n",
      "epoch: 8/100, loss = 1.323635\n",
      "epoch: 9/100, loss = 1.310142\n",
      "epoch: 10/100, loss = 1.297719\n",
      "epoch: 11/100, loss = 1.284739\n",
      "epoch: 12/100, loss = 1.276516\n",
      "epoch: 13/100, loss = 1.269326\n",
      "epoch: 14/100, loss = 1.260961\n",
      "epoch: 15/100, loss = 1.254827\n",
      "epoch: 16/100, loss = 1.246248\n",
      "epoch: 17/100, loss = 1.239866\n",
      "epoch: 18/100, loss = 1.232297\n",
      "epoch: 19/100, loss = 1.226155\n",
      "epoch: 20/100, loss = 1.220984\n",
      "epoch: 21/100, loss = 1.214649\n",
      "epoch: 22/100, loss = 1.207650\n",
      "epoch: 23/100, loss = 1.201822\n",
      "epoch: 24/100, loss = 1.194959\n",
      "epoch: 25/100, loss = 1.191230\n",
      "epoch: 26/100, loss = 1.184407\n",
      "epoch: 27/100, loss = 1.179370\n",
      "epoch: 28/100, loss = 1.175357\n",
      "epoch: 29/100, loss = 1.168760\n",
      "epoch: 30/100, loss = 1.165686\n",
      "epoch: 31/100, loss = 1.161779\n",
      "epoch: 32/100, loss = 1.154682\n",
      "epoch: 33/100, loss = 1.152491\n",
      "epoch: 34/100, loss = 1.147528\n",
      "epoch: 35/100, loss = 1.144800\n",
      "epoch: 36/100, loss = 1.139488\n",
      "epoch: 37/100, loss = 1.136426\n",
      "epoch: 38/100, loss = 1.131380\n",
      "epoch: 39/100, loss = 1.127192\n",
      "epoch: 40/100, loss = 1.125417\n",
      "epoch: 41/100, loss = 1.119873\n",
      "epoch: 42/100, loss = 1.116407\n",
      "epoch: 43/100, loss = 1.113128\n",
      "epoch: 44/100, loss = 1.109662\n",
      "epoch: 45/100, loss = 1.105390\n",
      "epoch: 46/100, loss = 1.103008\n",
      "epoch: 47/100, loss = 1.099385\n",
      "epoch: 48/100, loss = 1.091758\n",
      "epoch: 49/100, loss = 1.090626\n",
      "epoch: 50/100, loss = 1.085890\n",
      "epoch: 51/100, loss = 1.082704\n",
      "epoch: 52/100, loss = 1.078452\n",
      "epoch: 53/100, loss = 1.075592\n",
      "epoch: 54/100, loss = 1.072347\n",
      "epoch: 55/100, loss = 1.068914\n",
      "epoch: 56/100, loss = 1.065273\n",
      "epoch: 57/100, loss = 1.061683\n",
      "epoch: 58/100, loss = 1.061276\n",
      "epoch: 59/100, loss = 1.056977\n",
      "epoch: 60/100, loss = 1.055224\n",
      "epoch: 61/100, loss = 1.052471\n",
      "epoch: 62/100, loss = 1.048471\n",
      "epoch: 63/100, loss = 1.044234\n",
      "epoch: 64/100, loss = 1.045306\n",
      "epoch: 65/100, loss = 1.041004\n",
      "epoch: 66/100, loss = 1.037568\n",
      "epoch: 67/100, loss = 1.036267\n",
      "epoch: 68/100, loss = 1.030328\n",
      "epoch: 69/100, loss = 1.029278\n",
      "epoch: 70/100, loss = 1.027582\n",
      "epoch: 71/100, loss = 1.022966\n",
      "epoch: 72/100, loss = 1.022817\n",
      "epoch: 73/100, loss = 1.016824\n",
      "epoch: 74/100, loss = 1.014781\n",
      "epoch: 75/100, loss = 1.015897\n",
      "epoch: 76/100, loss = 1.012086\n",
      "epoch: 77/100, loss = 1.007039\n",
      "epoch: 78/100, loss = 1.004783\n",
      "epoch: 79/100, loss = 1.005293\n",
      "epoch: 80/100, loss = 1.003057\n",
      "epoch: 81/100, loss = 1.005661\n",
      "epoch: 82/100, loss = 0.998960\n",
      "epoch: 83/100, loss = 0.996776\n",
      "epoch: 84/100, loss = 0.995545\n",
      "epoch: 85/100, loss = 0.991313\n",
      "epoch: 86/100, loss = 0.989726\n",
      "epoch: 87/100, loss = 0.991134\n",
      "epoch: 88/100, loss = 0.986047\n",
      "epoch: 89/100, loss = 0.983375\n",
      "epoch: 90/100, loss = 0.979921\n",
      "epoch: 91/100, loss = 0.978486\n",
      "epoch: 92/100, loss = 0.975430\n",
      "epoch: 93/100, loss = 0.976023\n",
      "epoch: 94/100, loss = 0.972599\n",
      "epoch: 95/100, loss = 0.971566\n",
      "epoch: 96/100, loss = 0.968688\n",
      "epoch: 97/100, loss = 0.968776\n",
      "epoch: 98/100, loss = 0.970117\n",
      "epoch: 99/100, loss = 0.966764\n",
      "epoch: 100/100, loss = 0.963110\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num, dim) for num, dim in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_emb, 10),\n",
    "            torch.nn.BatchNorm1d(10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 5),\n",
    "            torch.nn.BatchNorm1d(5),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, 10),\n",
    "            torch.nn.BatchNorm1d(10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, n_emb),\n",
    "            torch.nn.BatchNorm1d(n_emb),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def embed(self, x_cat):\n",
    "        x_cat = x_cat.to(torch.long)\n",
    "        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        self.last_target = x.clone().detach()\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x_cat):\n",
    "        embedded = self.embed(x_cat)\n",
    "        encoded = self.encoder(embedded)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "model = EmbeddingModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for x_cat, x_cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_cat)\n",
    "        train_loss = criterion(outputs, model.last_target)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:35.135330Z",
     "end_time": "2023-06-25T22:36:35.140203Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.3175799 , 0.47763401, 0.27391624, ..., 0.63380282, 0.55681818,\n        0.        ],\n       [0.62006414, 0.49546278, 0.65352452, ..., 0.33802817, 0.46590909,\n        1.        ],\n       [0.34096557, 0.57605141, 0.44675148, ..., 0.48591549, 0.59090909,\n        0.66666667],\n       ...,\n       [0.07604529, 0.93895268, 0.36377221, ..., 0.66197183, 0.29545455,\n        0.24776501],\n       [0.25997174, 0.55062395, 0.51040393, ..., 0.28169014, 0.29545455,\n        0.24776501],\n       [0.53415155, 0.34326372, 0.21084449, ..., 0.23239437, 0.29545455,\n        0.24776501]])"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = model.encoder(model.embed(torch.tensor(df_no_min_max[categorial_columns].values, dtype=torch.float))).detach().numpy()\n",
    "emb_features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.210855\n",
      "epoch: 2/100, loss = 0.203398\n",
      "epoch: 3/100, loss = 0.195978\n",
      "epoch: 4/100, loss = 0.187806\n",
      "epoch: 5/100, loss = 0.180817\n",
      "epoch: 6/100, loss = 0.173674\n",
      "epoch: 7/100, loss = 0.167455\n",
      "epoch: 8/100, loss = 0.160880\n",
      "epoch: 9/100, loss = 0.154685\n",
      "epoch: 10/100, loss = 0.148660\n",
      "epoch: 11/100, loss = 0.142613\n",
      "epoch: 12/100, loss = 0.137596\n",
      "epoch: 13/100, loss = 0.131756\n",
      "epoch: 14/100, loss = 0.126135\n",
      "epoch: 15/100, loss = 0.121402\n",
      "epoch: 16/100, loss = 0.117029\n",
      "epoch: 17/100, loss = 0.112778\n",
      "epoch: 18/100, loss = 0.109128\n",
      "epoch: 19/100, loss = 0.105581\n",
      "epoch: 20/100, loss = 0.102827\n",
      "epoch: 21/100, loss = 0.100434\n",
      "epoch: 22/100, loss = 0.097961\n",
      "epoch: 23/100, loss = 0.096113\n",
      "epoch: 24/100, loss = 0.093927\n",
      "epoch: 25/100, loss = 0.091757\n",
      "epoch: 26/100, loss = 0.090151\n",
      "epoch: 27/100, loss = 0.088443\n",
      "epoch: 28/100, loss = 0.086686\n",
      "epoch: 29/100, loss = 0.084977\n",
      "epoch: 30/100, loss = 0.083755\n",
      "epoch: 31/100, loss = 0.082002\n",
      "epoch: 32/100, loss = 0.080793\n",
      "epoch: 33/100, loss = 0.079550\n",
      "epoch: 34/100, loss = 0.078264\n",
      "epoch: 35/100, loss = 0.077159\n",
      "epoch: 36/100, loss = 0.076389\n",
      "epoch: 37/100, loss = 0.075264\n",
      "epoch: 38/100, loss = 0.074493\n",
      "epoch: 39/100, loss = 0.074156\n",
      "epoch: 40/100, loss = 0.072898\n",
      "epoch: 41/100, loss = 0.072003\n",
      "epoch: 42/100, loss = 0.071264\n",
      "epoch: 43/100, loss = 0.070873\n",
      "epoch: 44/100, loss = 0.069789\n",
      "epoch: 45/100, loss = 0.069288\n",
      "epoch: 46/100, loss = 0.068568\n",
      "epoch: 47/100, loss = 0.068126\n",
      "epoch: 48/100, loss = 0.066950\n",
      "epoch: 49/100, loss = 0.066565\n",
      "epoch: 50/100, loss = 0.066156\n",
      "epoch: 51/100, loss = 0.065263\n",
      "epoch: 52/100, loss = 0.065187\n",
      "epoch: 53/100, loss = 0.064164\n",
      "epoch: 54/100, loss = 0.063891\n",
      "epoch: 55/100, loss = 0.063058\n",
      "epoch: 56/100, loss = 0.062382\n",
      "epoch: 57/100, loss = 0.062004\n",
      "epoch: 58/100, loss = 0.061643\n",
      "epoch: 59/100, loss = 0.061091\n",
      "epoch: 60/100, loss = 0.060798\n",
      "epoch: 61/100, loss = 0.059999\n",
      "epoch: 62/100, loss = 0.059492\n",
      "epoch: 63/100, loss = 0.059003\n",
      "epoch: 64/100, loss = 0.058698\n",
      "epoch: 65/100, loss = 0.058234\n",
      "epoch: 66/100, loss = 0.057638\n",
      "epoch: 67/100, loss = 0.056918\n",
      "epoch: 68/100, loss = 0.057462\n",
      "epoch: 69/100, loss = 0.056305\n",
      "epoch: 70/100, loss = 0.055785\n",
      "epoch: 71/100, loss = 0.055332\n",
      "epoch: 72/100, loss = 0.055183\n",
      "epoch: 73/100, loss = 0.054571\n",
      "epoch: 74/100, loss = 0.053938\n",
      "epoch: 75/100, loss = 0.053839\n",
      "epoch: 76/100, loss = 0.053320\n",
      "epoch: 77/100, loss = 0.052544\n",
      "epoch: 78/100, loss = 0.052333\n",
      "epoch: 79/100, loss = 0.051570\n",
      "epoch: 80/100, loss = 0.052235\n",
      "epoch: 81/100, loss = 0.051003\n",
      "epoch: 82/100, loss = 0.050647\n",
      "epoch: 83/100, loss = 0.050407\n",
      "epoch: 84/100, loss = 0.049909\n",
      "epoch: 85/100, loss = 0.049399\n",
      "epoch: 86/100, loss = 0.049608\n",
      "epoch: 87/100, loss = 0.048615\n",
      "epoch: 88/100, loss = 0.048321\n",
      "epoch: 89/100, loss = 0.048197\n",
      "epoch: 90/100, loss = 0.048192\n",
      "epoch: 91/100, loss = 0.047693\n",
      "epoch: 92/100, loss = 0.046921\n",
      "epoch: 93/100, loss = 0.046455\n",
      "epoch: 94/100, loss = 0.046363\n",
      "epoch: 95/100, loss = 0.046014\n",
      "epoch: 96/100, loss = 0.045467\n",
      "epoch: 97/100, loss = 0.045210\n",
      "epoch: 98/100, loss = 0.045158\n",
      "epoch: 99/100, loss = 0.044369\n",
      "epoch: 100/100, loss = 0.044121\n"
     ]
    }
   ],
   "source": [
    "class NoEmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(categorial_columns), 4),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, len(categorial_columns)),\n",
    "            torch.nn.BatchNorm1d(len(categorial_columns)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "no_emb_model = NoEmbeddingModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(no_emb_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    no_emb_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for x_cat, x_cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = no_emb_model(x_cat)\n",
    "        train_loss = criterion(outputs,  x_cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:35.143204Z",
     "end_time": "2023-06-25T22:36:36.099381Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.63290638, 0.58673674, 0.0487307 , ..., 0.63380282, 0.55681818,\n        0.        ],\n       [0.80592299, 0.29343107, 0.30010173, ..., 0.33802817, 0.46590909,\n        1.        ],\n       [0.74926722, 0.24845929, 0.34675065, ..., 0.48591549, 0.59090909,\n        0.66666667],\n       ...,\n       [0.4066658 , 0.60128987, 0.79905474, ..., 0.66197183, 0.29545455,\n        0.24776501],\n       [0.63790715, 0.59232634, 0.63531697, ..., 0.28169014, 0.29545455,\n        0.24776501],\n       [0.30170631, 0.50384915, 0.60135478, ..., 0.23239437, 0.29545455,\n        0.24776501]])"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = no_emb_model.encoder(torch.tensor(df_no_min_max[categorial_columns].values, dtype=torch.float)).detach().numpy()\n",
    "no_emb_features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "no_emb_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:36.100381Z",
     "end_time": "2023-06-25T22:36:36.105891Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:36.107891Z",
     "end_time": "2023-06-25T22:36:36.125335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catergorial Embeddings Accuracy: 0.30363864491844417\n",
      "No Embeddings Accuracy: 0.3613550815558344\n"
     ]
    }
   ],
   "source": [
    "emb_kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(emb_features)\n",
    "no_emb_kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(no_emb_features)\n",
    "\n",
    "emb_acc = cluster_accuracy(emb_kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "no_emb_acc = cluster_accuracy(no_emb_kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "\n",
    "print(f\"Catergorial Embeddings Accuracy: {emb_acc}\")\n",
    "print(f\"No Embeddings Accuracy: {no_emb_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T22:36:36.126342Z",
     "end_time": "2023-06-25T22:36:36.143451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings NMI: 0.08307825924411819\n",
      "No Embeddings NMI: 0.16834914289030875\n"
     ]
    }
   ],
   "source": [
    "emb_nmi = normalized_mutual_info_score(og_df[\"num\"].to_numpy(), emb_kmeans.labels_)\n",
    "no_emb_nmi = normalized_mutual_info_score(og_df[\"num\"].to_numpy(), no_emb_kmeans.labels_)\n",
    "\n",
    "print(f\"Embeddings NMI: {emb_nmi}\")\n",
    "print(f\"No Embeddings NMI: {no_emb_nmi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
