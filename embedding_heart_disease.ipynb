{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.872146Z",
     "end_time": "2023-06-25T15:19:57.879705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.876709Z",
     "end_time": "2023-06-25T15:19:57.902058Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_accuracy(y_pred, y_true):\n",
    "    # We need to map the labels to our cluster labels\n",
    "    # This is a linear assignment problem on a bipartite graph\n",
    "    k = max(len(np.unique(y_pred)), len(np.unique(y_pred)))\n",
    "    cost_matrix = np.zeros((k, k))\n",
    "    for i in range(y_pred.size):\n",
    "        cost_matrix[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix.max() - cost_matrix)\n",
    "    return cost_matrix[row_ind, col_ind].sum() / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.886545Z",
     "end_time": "2023-06-25T15:19:57.924546Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     age     sex               cp  trestbps   chol    fbs           restecg   \n0     63    Male   typical angina     145.0  233.0   True    lv hypertrophy  \\\n1     67    Male     asymptomatic     160.0  286.0  False    lv hypertrophy   \n2     67    Male     asymptomatic     120.0  229.0  False    lv hypertrophy   \n3     37    Male      non-anginal     130.0  250.0  False            normal   \n5     56    Male  atypical angina     120.0  236.0  False            normal   \n..   ...     ...              ...       ...    ...    ...               ...   \n913   62    Male     asymptomatic     158.0  170.0  False  st-t abnormality   \n914   46    Male     asymptomatic     134.0  310.0  False            normal   \n915   54  Female     asymptomatic     127.0  333.0   True  st-t abnormality   \n917   55    Male     asymptomatic     122.0  223.0   True  st-t abnormality   \n919   62    Male  atypical angina     120.0  254.0  False    lv hypertrophy   \n\n     thalch  exang  oldpeak        slope   ca               thal  num  \n0     150.0  False      2.3  downsloping  0.0       fixed defect    0  \n1     108.0   True      1.5         flat  3.0             normal    2  \n2     129.0   True      2.6         flat  2.0  reversable defect    1  \n3     187.0  False      3.5  downsloping  0.0             normal    0  \n5     178.0  False      0.8    upsloping  0.0             normal    0  \n..      ...    ...      ...          ...  ...                ...  ...  \n913   138.0   True      0.0          NaN  NaN                NaN    1  \n914   126.0  False      0.0          NaN  NaN             normal    2  \n915   154.0  False      0.0          NaN  NaN                NaN    1  \n917   100.0  False      0.0          NaN  NaN       fixed defect    2  \n919    93.0   True      0.0          NaN  NaN                NaN    1  \n\n[797 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>Male</td>\n      <td>typical angina</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>True</td>\n      <td>lv hypertrophy</td>\n      <td>150.0</td>\n      <td>False</td>\n      <td>2.3</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>fixed defect</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>108.0</td>\n      <td>True</td>\n      <td>1.5</td>\n      <td>flat</td>\n      <td>3.0</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>129.0</td>\n      <td>True</td>\n      <td>2.6</td>\n      <td>flat</td>\n      <td>2.0</td>\n      <td>reversable defect</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>Male</td>\n      <td>non-anginal</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>187.0</td>\n      <td>False</td>\n      <td>3.5</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>236.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>178.0</td>\n      <td>False</td>\n      <td>0.8</td>\n      <td>upsloping</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>158.0</td>\n      <td>170.0</td>\n      <td>False</td>\n      <td>st-t abnormality</td>\n      <td>138.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>46</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>134.0</td>\n      <td>310.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>126.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>Female</td>\n      <td>asymptomatic</td>\n      <td>127.0</td>\n      <td>333.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>154.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>122.0</td>\n      <td>223.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>100.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>fixed defect</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>254.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>93.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(\"datasets/heart_disease_uci.csv\")\n",
    "og_df.drop(columns=[\"id\", \"dataset\"], inplace=True)\n",
    "og_df = og_df.drop(og_df[og_df[\"num\"] == 0].sample(frac=0.3).index)\n",
    "og_df # this df still has \"num\" -> the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.907399Z",
     "end_time": "2023-06-25T15:19:57.924546Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorial_columns = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\"]\n",
    "cont_columns = [\"age\", \"trestbps\", \"chol\", \"thalch\", \"oldpeak\", \"ca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.911688Z",
     "end_time": "2023-06-25T15:19:57.935583Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          age  sex        cp  trestbps      chol  fbs   restecg    thalch   \n0    0.714286  1.0  1.000000     0.725  0.386401  0.5  0.000000  0.633803  \\\n1    0.795918  1.0  0.000000     0.800  0.474295  0.0  0.000000  0.338028   \n2    0.795918  1.0  0.000000     0.600  0.379768  0.0  0.000000  0.485915   \n3    0.183673  1.0  0.666667     0.650  0.414594  0.0  0.333333  0.894366   \n5    0.571429  1.0  0.333333     0.600  0.391376  0.0  0.333333  0.830986   \n..        ...  ...       ...       ...       ...  ...       ...       ...   \n913  0.693878  1.0  0.000000     0.790  0.281924  0.0  0.666667  0.549296   \n914  0.367347  1.0  0.000000     0.670  0.514096  0.0  0.333333  0.464789   \n915  0.530612  0.0  0.000000     0.635  0.552239  0.5  0.666667  0.661972   \n917  0.551020  1.0  0.000000     0.610  0.369818  0.5  0.666667  0.281690   \n919  0.693878  1.0  0.333333     0.600  0.421227  0.0  0.000000  0.232394   \n\n     exang   oldpeak     slope        ca      thal  \n0      0.0  0.556818  0.000000  0.000000  0.000000  \n1      0.5  0.465909  0.333333  1.000000  0.333333  \n2      0.5  0.590909  0.333333  0.666667  0.666667  \n3      0.0  0.693182  0.000000  0.000000  0.333333  \n5      0.0  0.386364  0.666667  0.000000  0.333333  \n..     ...       ...       ...       ...       ...  \n913    0.5  0.295455  1.000000  0.248092  1.000000  \n914    0.0  0.295455  1.000000  0.248092  0.333333  \n915    0.0  0.295455  1.000000  0.248092  1.000000  \n917    0.0  0.295455  1.000000  0.248092  0.000000  \n919    0.5  0.295455  1.000000  0.248092  1.000000  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.714286</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.725</td>\n      <td>0.386401</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.633803</td>\n      <td>0.0</td>\n      <td>0.556818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.800</td>\n      <td>0.474295</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.338028</td>\n      <td>0.5</td>\n      <td>0.465909</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.600</td>\n      <td>0.379768</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.485915</td>\n      <td>0.5</td>\n      <td>0.590909</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.183673</td>\n      <td>1.0</td>\n      <td>0.666667</td>\n      <td>0.650</td>\n      <td>0.414594</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.894366</td>\n      <td>0.0</td>\n      <td>0.693182</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.571429</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600</td>\n      <td>0.391376</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.830986</td>\n      <td>0.0</td>\n      <td>0.386364</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.790</td>\n      <td>0.281924</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.549296</td>\n      <td>0.5</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248092</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>0.367347</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.670</td>\n      <td>0.514096</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.464789</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248092</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0.530612</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.635</td>\n      <td>0.552239</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.661972</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248092</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>0.551020</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.610</td>\n      <td>0.369818</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.281690</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248092</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600</td>\n      <td>0.421227</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.232394</td>\n      <td>0.5</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248092</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_max = og_df.copy()\n",
    "df_min_max.drop(columns=\"num\", inplace=True)\n",
    "df_min_max[categorial_columns] = df_min_max[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df_min_max[categorial_columns] = MinMaxScaler().fit_transform(df_min_max[categorial_columns])\n",
    "df_min_max[cont_columns] = MinMaxScaler().fit_transform(df_min_max[cont_columns])\n",
    "df_min_max = df_min_max.fillna(df_min_max.mean())\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.937585Z",
     "end_time": "2023-06-25T15:19:57.960909Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps   chol  fbs  restecg  thalch  exang  oldpeak   \n0     63    1   3     145.0  233.0    1        0   150.0      0      2.3  \\\n1     67    1   0     160.0  286.0    0        0   108.0      1      1.5   \n2     67    1   0     120.0  229.0    0        0   129.0      1      2.6   \n3     37    1   2     130.0  250.0    0        1   187.0      0      3.5   \n5     56    1   1     120.0  236.0    0        1   178.0      0      0.8   \n..   ...  ...  ..       ...    ...  ...      ...     ...    ...      ...   \n913   62    1   0     158.0  170.0    0        2   138.0      1      0.0   \n914   46    1   0     134.0  310.0    0        1   126.0      0      0.0   \n915   54    0   0     127.0  333.0    1        2   154.0      0      0.0   \n917   55    1   0     122.0  223.0    1        2   100.0      0      0.0   \n919   62    1   1     120.0  254.0    0        0    93.0      1      0.0   \n\n     slope        ca  thal  \n0        0  0.000000     0  \n1        1  3.000000     1  \n2        1  2.000000     2  \n3        0  0.000000     1  \n5        2  0.000000     1  \n..     ...       ...   ...  \n913      3  0.744275     3  \n914      3  0.744275     1  \n915      3  0.744275     3  \n917      3  0.744275     0  \n919      3  0.744275     3  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150.0</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.0</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>3.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>129.0</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187.0</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>236.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178.0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>913</th>\n      <td>62</td>\n      <td>1</td>\n      <td>0</td>\n      <td>158.0</td>\n      <td>170.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>138.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.744275</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>46</td>\n      <td>1</td>\n      <td>0</td>\n      <td>134.0</td>\n      <td>310.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>126.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.744275</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>0</td>\n      <td>0</td>\n      <td>127.0</td>\n      <td>333.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>154.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.744275</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>122.0</td>\n      <td>223.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.744275</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>254.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.744275</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_min_max = og_df.copy()\n",
    "df_no_min_max.drop(columns=\"num\", inplace=True)\n",
    "df_no_min_max[categorial_columns] = df_no_min_max[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df_no_min_max = df_no_min_max.fillna(df_no_min_max.mean())\n",
    "df_no_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.951402Z",
     "end_time": "2023-06-25T15:19:57.995260Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HeartDiseaseDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.cat = torch.tensor(df[categorial_columns].values, dtype=torch.float)\n",
    "        self.cont = torch.tensor(df[cont_columns].values, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cat[idx], self.cont[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.955909Z",
     "end_time": "2023-06-25T15:19:58.004766Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "797"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = HeartDiseaseDataset(df_min_max)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.968605Z",
     "end_time": "2023-06-25T15:19:58.019280Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[(2, 2), (4, 2), (3, 2), (4, 2), (3, 2), (4, 2), (4, 2)]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(df_no_min_max[col].nunique(), min(50, max(2, (df_no_min_max[col].nunique()+1) // 2))) for col in df_no_min_max[categorial_columns]]\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:57.981220Z",
     "end_time": "2023-06-25T15:19:59.788842Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.795293\n",
      "epoch: 2/100, loss = 0.770563\n",
      "epoch: 3/100, loss = 0.750318\n",
      "epoch: 4/100, loss = 0.736437\n",
      "epoch: 5/100, loss = 0.727786\n",
      "epoch: 6/100, loss = 0.718838\n",
      "epoch: 7/100, loss = 0.709963\n",
      "epoch: 8/100, loss = 0.699951\n",
      "epoch: 9/100, loss = 0.691608\n",
      "epoch: 10/100, loss = 0.683843\n",
      "epoch: 11/100, loss = 0.677747\n",
      "epoch: 12/100, loss = 0.671137\n",
      "epoch: 13/100, loss = 0.665922\n",
      "epoch: 14/100, loss = 0.660093\n",
      "epoch: 15/100, loss = 0.652843\n",
      "epoch: 16/100, loss = 0.647953\n",
      "epoch: 17/100, loss = 0.644660\n",
      "epoch: 18/100, loss = 0.640733\n",
      "epoch: 19/100, loss = 0.635961\n",
      "epoch: 20/100, loss = 0.631048\n",
      "epoch: 21/100, loss = 0.628197\n",
      "epoch: 22/100, loss = 0.624059\n",
      "epoch: 23/100, loss = 0.619593\n",
      "epoch: 24/100, loss = 0.616334\n",
      "epoch: 25/100, loss = 0.612968\n",
      "epoch: 26/100, loss = 0.608987\n",
      "epoch: 27/100, loss = 0.605439\n",
      "epoch: 28/100, loss = 0.601901\n",
      "epoch: 29/100, loss = 0.597742\n",
      "epoch: 30/100, loss = 0.594111\n",
      "epoch: 31/100, loss = 0.590337\n",
      "epoch: 32/100, loss = 0.585969\n",
      "epoch: 33/100, loss = 0.581315\n",
      "epoch: 34/100, loss = 0.577437\n",
      "epoch: 35/100, loss = 0.573989\n",
      "epoch: 36/100, loss = 0.571308\n",
      "epoch: 37/100, loss = 0.568686\n",
      "epoch: 38/100, loss = 0.565906\n",
      "epoch: 39/100, loss = 0.562697\n",
      "epoch: 40/100, loss = 0.558771\n",
      "epoch: 41/100, loss = 0.555310\n",
      "epoch: 42/100, loss = 0.553895\n",
      "epoch: 43/100, loss = 0.550979\n",
      "epoch: 44/100, loss = 0.548707\n",
      "epoch: 45/100, loss = 0.546154\n",
      "epoch: 46/100, loss = 0.544256\n",
      "epoch: 47/100, loss = 0.541935\n",
      "epoch: 48/100, loss = 0.539375\n",
      "epoch: 49/100, loss = 0.538273\n",
      "epoch: 50/100, loss = 0.534397\n",
      "epoch: 51/100, loss = 0.532209\n",
      "epoch: 52/100, loss = 0.530365\n",
      "epoch: 53/100, loss = 0.529840\n",
      "epoch: 54/100, loss = 0.525515\n",
      "epoch: 55/100, loss = 0.523494\n",
      "epoch: 56/100, loss = 0.523539\n",
      "epoch: 57/100, loss = 0.519587\n",
      "epoch: 58/100, loss = 0.518635\n",
      "epoch: 59/100, loss = 0.514741\n",
      "epoch: 60/100, loss = 0.513718\n",
      "epoch: 61/100, loss = 0.511552\n",
      "epoch: 62/100, loss = 0.511398\n",
      "epoch: 63/100, loss = 0.506767\n",
      "epoch: 64/100, loss = 0.508881\n",
      "epoch: 65/100, loss = 0.502249\n",
      "epoch: 66/100, loss = 0.500364\n",
      "epoch: 67/100, loss = 0.500668\n",
      "epoch: 68/100, loss = 0.496624\n",
      "epoch: 69/100, loss = 0.493589\n",
      "epoch: 70/100, loss = 0.491767\n",
      "epoch: 71/100, loss = 0.492467\n",
      "epoch: 72/100, loss = 0.488357\n",
      "epoch: 73/100, loss = 0.487166\n",
      "epoch: 74/100, loss = 0.486014\n",
      "epoch: 75/100, loss = 0.483866\n",
      "epoch: 76/100, loss = 0.480448\n",
      "epoch: 77/100, loss = 0.479715\n",
      "epoch: 78/100, loss = 0.477362\n",
      "epoch: 79/100, loss = 0.475359\n",
      "epoch: 80/100, loss = 0.474805\n",
      "epoch: 81/100, loss = 0.477157\n",
      "epoch: 82/100, loss = 0.471630\n",
      "epoch: 83/100, loss = 0.470042\n",
      "epoch: 84/100, loss = 0.470928\n",
      "epoch: 85/100, loss = 0.464728\n",
      "epoch: 86/100, loss = 0.464306\n",
      "epoch: 87/100, loss = 0.461905\n",
      "epoch: 88/100, loss = 0.458474\n",
      "epoch: 89/100, loss = 0.456929\n",
      "epoch: 90/100, loss = 0.456352\n",
      "epoch: 91/100, loss = 0.451596\n",
      "epoch: 92/100, loss = 0.449713\n",
      "epoch: 93/100, loss = 0.448966\n",
      "epoch: 94/100, loss = 0.448221\n",
      "epoch: 95/100, loss = 0.448542\n",
      "epoch: 96/100, loss = 0.444221\n",
      "epoch: 97/100, loss = 0.446246\n",
      "epoch: 98/100, loss = 0.442436\n",
      "epoch: 99/100, loss = 0.440418\n",
      "epoch: 100/100, loss = 0.441653\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num, dim) for num, dim in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_emb, 10),\n",
    "            torch.nn.BatchNorm1d(10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 5),\n",
    "            torch.nn.BatchNorm1d(5),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, 10),\n",
    "            torch.nn.BatchNorm1d(10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, n_emb),\n",
    "            torch.nn.BatchNorm1d(n_emb),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def embed(self, x_cat):\n",
    "        x_cat = x_cat.to(torch.long)\n",
    "        x = [e(x_cat[:, i]) for i, e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        self.last_target = x.clone().detach()\n",
    "        return x\n",
    "\n",
    "\n",
    "    def forward(self, x_cat):\n",
    "        embedded = self.embed(x_cat)\n",
    "        encoded = self.encoder(embedded)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "model = EmbeddingModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for x_cat, x_cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_cat)\n",
    "        train_loss = criterion(outputs, model.last_target)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:59.791842Z",
     "end_time": "2023-06-25T15:19:59.795904Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.48061433, 0.80400318, 0.25544319, ..., 0.63380282, 0.55681818,\n        0.        ],\n       [0.70400512, 0.58711112, 0.48211822, ..., 0.33802817, 0.46590909,\n        1.        ],\n       [0.72711879, 0.4867419 , 0.61616045, ..., 0.48591549, 0.59090909,\n        0.66666667],\n       ...,\n       [0.67904365, 0.68620634, 0.15941194, ..., 0.66197183, 0.29545455,\n        0.2480916 ],\n       [0.69987154, 0.57911009, 0.14512829, ..., 0.28169014, 0.29545455,\n        0.2480916 ],\n       [0.54435116, 0.78236496, 0.59793109, ..., 0.23239437, 0.29545455,\n        0.2480916 ]])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = model.encoder(model.embed(torch.tensor(df_no_min_max[categorial_columns].values, dtype=torch.float))).detach().numpy()\n",
    "emb_features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "emb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.197067\n",
      "epoch: 2/100, loss = 0.191220\n",
      "epoch: 3/100, loss = 0.185232\n",
      "epoch: 4/100, loss = 0.179241\n",
      "epoch: 5/100, loss = 0.173658\n",
      "epoch: 6/100, loss = 0.167935\n",
      "epoch: 7/100, loss = 0.162461\n",
      "epoch: 8/100, loss = 0.157426\n",
      "epoch: 9/100, loss = 0.151830\n",
      "epoch: 10/100, loss = 0.147336\n",
      "epoch: 11/100, loss = 0.142164\n",
      "epoch: 12/100, loss = 0.137716\n",
      "epoch: 13/100, loss = 0.133678\n",
      "epoch: 14/100, loss = 0.129417\n",
      "epoch: 15/100, loss = 0.126173\n",
      "epoch: 16/100, loss = 0.122769\n",
      "epoch: 17/100, loss = 0.119017\n",
      "epoch: 18/100, loss = 0.115702\n",
      "epoch: 19/100, loss = 0.113489\n",
      "epoch: 20/100, loss = 0.110744\n",
      "epoch: 21/100, loss = 0.108096\n",
      "epoch: 22/100, loss = 0.105553\n",
      "epoch: 23/100, loss = 0.103768\n",
      "epoch: 24/100, loss = 0.101399\n",
      "epoch: 25/100, loss = 0.099643\n",
      "epoch: 26/100, loss = 0.097829\n",
      "epoch: 27/100, loss = 0.096570\n",
      "epoch: 28/100, loss = 0.094603\n",
      "epoch: 29/100, loss = 0.093493\n",
      "epoch: 30/100, loss = 0.091935\n",
      "epoch: 31/100, loss = 0.090519\n",
      "epoch: 32/100, loss = 0.089148\n",
      "epoch: 33/100, loss = 0.088132\n",
      "epoch: 34/100, loss = 0.086687\n",
      "epoch: 35/100, loss = 0.085662\n",
      "epoch: 36/100, loss = 0.084530\n",
      "epoch: 37/100, loss = 0.083433\n",
      "epoch: 38/100, loss = 0.082376\n",
      "epoch: 39/100, loss = 0.081208\n",
      "epoch: 40/100, loss = 0.079909\n",
      "epoch: 41/100, loss = 0.079349\n",
      "epoch: 42/100, loss = 0.078029\n",
      "epoch: 43/100, loss = 0.076735\n",
      "epoch: 44/100, loss = 0.075826\n",
      "epoch: 45/100, loss = 0.074529\n",
      "epoch: 46/100, loss = 0.073607\n",
      "epoch: 47/100, loss = 0.072505\n",
      "epoch: 48/100, loss = 0.071291\n",
      "epoch: 49/100, loss = 0.070227\n",
      "epoch: 50/100, loss = 0.069018\n",
      "epoch: 51/100, loss = 0.068090\n",
      "epoch: 52/100, loss = 0.066864\n",
      "epoch: 53/100, loss = 0.065837\n",
      "epoch: 54/100, loss = 0.064865\n",
      "epoch: 55/100, loss = 0.063876\n",
      "epoch: 56/100, loss = 0.062896\n",
      "epoch: 57/100, loss = 0.061918\n",
      "epoch: 58/100, loss = 0.060965\n",
      "epoch: 59/100, loss = 0.060154\n",
      "epoch: 60/100, loss = 0.059755\n",
      "epoch: 61/100, loss = 0.058932\n",
      "epoch: 62/100, loss = 0.058286\n",
      "epoch: 63/100, loss = 0.057559\n",
      "epoch: 64/100, loss = 0.056780\n",
      "epoch: 65/100, loss = 0.056787\n",
      "epoch: 66/100, loss = 0.055682\n",
      "epoch: 67/100, loss = 0.055279\n",
      "epoch: 68/100, loss = 0.054799\n",
      "epoch: 69/100, loss = 0.054402\n",
      "epoch: 70/100, loss = 0.053687\n",
      "epoch: 71/100, loss = 0.053327\n",
      "epoch: 72/100, loss = 0.052819\n",
      "epoch: 73/100, loss = 0.052496\n",
      "epoch: 74/100, loss = 0.051943\n",
      "epoch: 75/100, loss = 0.051525\n",
      "epoch: 76/100, loss = 0.051400\n",
      "epoch: 77/100, loss = 0.050702\n",
      "epoch: 78/100, loss = 0.050227\n",
      "epoch: 79/100, loss = 0.049740\n",
      "epoch: 80/100, loss = 0.049586\n",
      "epoch: 81/100, loss = 0.049041\n",
      "epoch: 82/100, loss = 0.048618\n",
      "epoch: 83/100, loss = 0.048208\n",
      "epoch: 84/100, loss = 0.048077\n",
      "epoch: 85/100, loss = 0.047694\n",
      "epoch: 86/100, loss = 0.047262\n",
      "epoch: 87/100, loss = 0.046965\n",
      "epoch: 88/100, loss = 0.046591\n",
      "epoch: 89/100, loss = 0.046471\n",
      "epoch: 90/100, loss = 0.045873\n",
      "epoch: 91/100, loss = 0.045291\n",
      "epoch: 92/100, loss = 0.045338\n",
      "epoch: 93/100, loss = 0.045223\n",
      "epoch: 94/100, loss = 0.045014\n",
      "epoch: 95/100, loss = 0.044455\n",
      "epoch: 96/100, loss = 0.043993\n",
      "epoch: 97/100, loss = 0.043868\n",
      "epoch: 98/100, loss = 0.043422\n",
      "epoch: 99/100, loss = 0.042929\n",
      "epoch: 100/100, loss = 0.043090\n"
     ]
    }
   ],
   "source": [
    "class NoEmbeddingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(categorial_columns), 4),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, len(categorial_columns)),\n",
    "            torch.nn.BatchNorm1d(len(categorial_columns)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "no_emb_model = NoEmbeddingModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(no_emb_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    no_emb_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for x_cat, x_cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = no_emb_model(x_cat)\n",
    "        train_loss = criterion(outputs,  x_cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T15:19:59.795904Z",
     "end_time": "2023-06-25T15:20:00.717528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.94438982, 0.96247274, 0.27103686, ..., 0.63380282, 0.55681818,\n        0.        ],\n       [0.33041218, 0.67214167, 0.27885282, ..., 0.33802817, 0.46590909,\n        1.        ],\n       [0.32576355, 0.61795926, 0.36475679, ..., 0.48591549, 0.59090909,\n        0.66666667],\n       ...,\n       [0.33899528, 0.10623961, 0.73014563, ..., 0.66197183, 0.29545455,\n        0.2480916 ],\n       [0.29100227, 0.58482736, 0.41327247, ..., 0.28169014, 0.29545455,\n        0.2480916 ],\n       [0.51337862, 0.62326276, 0.62623727, ..., 0.23239437, 0.29545455,\n        0.2480916 ]])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = no_emb_model.encoder(torch.tensor(df_no_min_max[categorial_columns].values, dtype=torch.float)).detach().numpy()\n",
    "no_emb_features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "no_emb_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T15:20:00.718527Z",
     "end_time": "2023-06-25T15:20:00.724565Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T15:20:00.726571Z",
     "end_time": "2023-06-25T15:20:00.747454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catergorial Embeddings Accuracy: 0.3174404015056462\n",
      "No Embeddings Accuracy: 0.33500627352572143\n"
     ]
    }
   ],
   "source": [
    "emb_kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(emb_features)\n",
    "no_emb_kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(no_emb_features)\n",
    "\n",
    "emb_acc = cluster_accuracy(emb_kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "no_emb_acc = cluster_accuracy(no_emb_kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "\n",
    "print(f\"Catergorial Embeddings Accuracy: {emb_acc}\")\n",
    "print(f\"No Embeddings Accuracy: {no_emb_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-25T15:20:00.743164Z",
     "end_time": "2023-06-25T15:20:00.753463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings NMI: 0.07183427997191377\n",
      "No Embeddings NMI: 0.1447807605488128\n"
     ]
    }
   ],
   "source": [
    "emb_nmi = normalized_mutual_info_score(og_df[\"num\"].to_numpy(), emb_kmeans.labels_)\n",
    "no_emb_nmi = normalized_mutual_info_score(og_df[\"num\"].to_numpy(), no_emb_kmeans.labels_)\n",
    "\n",
    "print(f\"Embeddings NMI: {emb_nmi}\")\n",
    "print(f\"No Embeddings NMI: {no_emb_nmi}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
