{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:38.156425500Z",
     "start_time": "2023-06-14T10:47:38.123302600Z"
    }
   },
   "outputs": [],
   "source": [
    "import gower\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "     age     sex               cp  trestbps   chol    fbs           restecg   \n0     63    Male   typical angina     145.0  233.0   True    lv hypertrophy  \\\n1     67    Male     asymptomatic     160.0  286.0  False    lv hypertrophy   \n2     67    Male     asymptomatic     120.0  229.0  False    lv hypertrophy   \n3     37    Male      non-anginal     130.0  250.0  False            normal   \n5     56    Male  atypical angina     120.0  236.0  False            normal   \n..   ...     ...              ...       ...    ...    ...               ...   \n914   46    Male     asymptomatic     134.0  310.0  False            normal   \n915   54  Female     asymptomatic     127.0  333.0   True  st-t abnormality   \n917   55    Male     asymptomatic     122.0  223.0   True  st-t abnormality   \n918   58    Male     asymptomatic       NaN  385.0   True    lv hypertrophy   \n919   62    Male  atypical angina     120.0  254.0  False    lv hypertrophy   \n\n     thalch  exang  oldpeak        slope   ca               thal  num  \n0     150.0  False      2.3  downsloping  0.0       fixed defect    0  \n1     108.0   True      1.5         flat  3.0             normal    2  \n2     129.0   True      2.6         flat  2.0  reversable defect    1  \n3     187.0  False      3.5  downsloping  0.0             normal    0  \n5     178.0  False      0.8    upsloping  0.0             normal    0  \n..      ...    ...      ...          ...  ...                ...  ...  \n914   126.0  False      0.0          NaN  NaN             normal    2  \n915   154.0  False      0.0          NaN  NaN                NaN    1  \n917   100.0  False      0.0          NaN  NaN       fixed defect    2  \n918     NaN    NaN      NaN          NaN  NaN                NaN    0  \n919    93.0   True      0.0          NaN  NaN                NaN    1  \n\n[797 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>Male</td>\n      <td>typical angina</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>True</td>\n      <td>lv hypertrophy</td>\n      <td>150.0</td>\n      <td>False</td>\n      <td>2.3</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>fixed defect</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>108.0</td>\n      <td>True</td>\n      <td>1.5</td>\n      <td>flat</td>\n      <td>3.0</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>129.0</td>\n      <td>True</td>\n      <td>2.6</td>\n      <td>flat</td>\n      <td>2.0</td>\n      <td>reversable defect</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>Male</td>\n      <td>non-anginal</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>187.0</td>\n      <td>False</td>\n      <td>3.5</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>56</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>236.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>178.0</td>\n      <td>False</td>\n      <td>0.8</td>\n      <td>upsloping</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>46</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>134.0</td>\n      <td>310.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>126.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>Female</td>\n      <td>asymptomatic</td>\n      <td>127.0</td>\n      <td>333.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>154.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>122.0</td>\n      <td>223.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>100.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>fixed defect</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>58</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>NaN</td>\n      <td>385.0</td>\n      <td>True</td>\n      <td>lv hypertrophy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>254.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>93.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(\"datasets/heart_disease_uci.csv\")\n",
    "og_df.drop(columns=[\"id\", \"dataset\"], inplace=True)\n",
    "og_df = og_df.drop(og_df[og_df[\"num\"] == 0].sample(frac=0.3).index)\n",
    "og_df # this df still has \"num\" -> the target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:38.182906900Z",
     "start_time": "2023-06-14T10:47:38.145064900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "categorial_columns = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\"]\n",
    "cont_columns = [\"age\", \"trestbps\", \"chol\", \"thalch\", \"oldpeak\", \"ca\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:38.199915400Z",
     "start_time": "2023-06-14T10:47:38.184907100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "          age  sex        cp  trestbps      chol  fbs   restecg    thalch   \n0    0.714286  1.0  1.000000  0.725000  0.386401  0.5  0.000000  0.633803  \\\n1    0.795918  1.0  0.000000  0.800000  0.474295  0.0  0.000000  0.338028   \n2    0.795918  1.0  0.000000  0.600000  0.379768  0.0  0.000000  0.485915   \n3    0.183673  1.0  0.666667  0.650000  0.414594  0.0  0.333333  0.894366   \n5    0.571429  1.0  0.333333  0.600000  0.391376  0.0  0.333333  0.830986   \n..        ...  ...       ...       ...       ...  ...       ...       ...   \n914  0.367347  1.0  0.000000  0.670000  0.514096  0.0  0.333333  0.464789   \n915  0.530612  0.0  0.000000  0.635000  0.552239  0.5  0.666667  0.661972   \n917  0.551020  1.0  0.000000  0.610000  0.369818  0.5  0.666667  0.281690   \n918  0.612245  1.0  0.000000  0.662949  0.638474  0.5  0.000000  0.537061   \n919  0.693878  1.0  0.333333  0.600000  0.421227  0.0  0.000000  0.232394   \n\n     exang   oldpeak     slope        ca      thal  \n0      0.0  0.556818  0.000000  0.000000  0.000000  \n1      0.5  0.465909  0.333333  1.000000  0.333333  \n2      0.5  0.590909  0.333333  0.666667  0.666667  \n3      0.0  0.693182  0.000000  0.000000  0.333333  \n5      0.0  0.386364  0.666667  0.000000  0.333333  \n..     ...       ...       ...       ...       ...  \n914    0.0  0.295455  1.000000  0.248737  0.333333  \n915    0.0  0.295455  1.000000  0.248737  1.000000  \n917    0.0  0.295455  1.000000  0.248737  0.000000  \n918    1.0  0.401989  1.000000  0.248737  1.000000  \n919    0.5  0.295455  1.000000  0.248737  1.000000  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.714286</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.725000</td>\n      <td>0.386401</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.633803</td>\n      <td>0.0</td>\n      <td>0.556818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.800000</td>\n      <td>0.474295</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.338028</td>\n      <td>0.5</td>\n      <td>0.465909</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.600000</td>\n      <td>0.379768</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.485915</td>\n      <td>0.5</td>\n      <td>0.590909</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.183673</td>\n      <td>1.0</td>\n      <td>0.666667</td>\n      <td>0.650000</td>\n      <td>0.414594</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.894366</td>\n      <td>0.0</td>\n      <td>0.693182</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.571429</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600000</td>\n      <td>0.391376</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.830986</td>\n      <td>0.0</td>\n      <td>0.386364</td>\n      <td>0.666667</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>914</th>\n      <td>0.367347</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.670000</td>\n      <td>0.514096</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.464789</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248737</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0.530612</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.635000</td>\n      <td>0.552239</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.661972</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248737</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>0.551020</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.610000</td>\n      <td>0.369818</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.281690</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248737</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>0.612245</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.662949</td>\n      <td>0.638474</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.537061</td>\n      <td>1.0</td>\n      <td>0.401989</td>\n      <td>1.000000</td>\n      <td>0.248737</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600000</td>\n      <td>0.421227</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.232394</td>\n      <td>0.5</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.248737</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = og_df.copy()\n",
    "df.drop(columns=\"num\", inplace=True)\n",
    "df[categorial_columns] = df[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df[categorial_columns] = MinMaxScaler().fit_transform(df[categorial_columns])\n",
    "\n",
    "df[cont_columns] = MinMaxScaler().fit_transform(df[cont_columns])\n",
    "df = df.fillna(df.mean())\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:38.258760600Z",
     "start_time": "2023-06-14T10:47:38.190725900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "class HeartDiseaseDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.cat = torch.tensor(df[categorial_columns].values, dtype=torch.float)\n",
    "        self.cont = torch.tensor(df[cont_columns].values, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cat[idx], self.cont[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cat.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:38.279858200Z",
     "start_time": "2023-06-14T10:47:38.237555900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "data": {
      "text/plain": "797"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = HeartDiseaseDataset(df)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:38.285840700Z",
     "start_time": "2023-06-14T10:47:38.237555900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.186713\n",
      "epoch: 2/100, loss = 0.176970\n",
      "epoch: 3/100, loss = 0.167061\n",
      "epoch: 4/100, loss = 0.158809\n",
      "epoch: 5/100, loss = 0.151612\n",
      "epoch: 6/100, loss = 0.143855\n",
      "epoch: 7/100, loss = 0.137120\n",
      "epoch: 8/100, loss = 0.131828\n",
      "epoch: 9/100, loss = 0.126819\n",
      "epoch: 10/100, loss = 0.122186\n",
      "epoch: 11/100, loss = 0.118201\n",
      "epoch: 12/100, loss = 0.114584\n",
      "epoch: 13/100, loss = 0.111063\n",
      "epoch: 14/100, loss = 0.108626\n",
      "epoch: 15/100, loss = 0.105471\n",
      "epoch: 16/100, loss = 0.102871\n",
      "epoch: 17/100, loss = 0.100204\n",
      "epoch: 18/100, loss = 0.098075\n",
      "epoch: 19/100, loss = 0.096051\n",
      "epoch: 20/100, loss = 0.094764\n",
      "epoch: 21/100, loss = 0.092822\n",
      "epoch: 22/100, loss = 0.090675\n",
      "epoch: 23/100, loss = 0.089213\n",
      "epoch: 24/100, loss = 0.087834\n",
      "epoch: 25/100, loss = 0.086339\n",
      "epoch: 26/100, loss = 0.085115\n",
      "epoch: 27/100, loss = 0.083893\n",
      "epoch: 28/100, loss = 0.082686\n",
      "epoch: 29/100, loss = 0.081733\n",
      "epoch: 30/100, loss = 0.080771\n",
      "epoch: 31/100, loss = 0.079553\n",
      "epoch: 32/100, loss = 0.079164\n",
      "epoch: 33/100, loss = 0.077602\n",
      "epoch: 34/100, loss = 0.076812\n",
      "epoch: 35/100, loss = 0.076216\n",
      "epoch: 36/100, loss = 0.075040\n",
      "epoch: 37/100, loss = 0.074124\n",
      "epoch: 38/100, loss = 0.073311\n",
      "epoch: 39/100, loss = 0.072397\n",
      "epoch: 40/100, loss = 0.071604\n",
      "epoch: 41/100, loss = 0.070616\n",
      "epoch: 42/100, loss = 0.070214\n",
      "epoch: 43/100, loss = 0.069221\n",
      "epoch: 44/100, loss = 0.068446\n",
      "epoch: 45/100, loss = 0.067864\n",
      "epoch: 46/100, loss = 0.067289\n",
      "epoch: 47/100, loss = 0.066760\n",
      "epoch: 48/100, loss = 0.065553\n",
      "epoch: 49/100, loss = 0.065125\n",
      "epoch: 50/100, loss = 0.064829\n",
      "epoch: 51/100, loss = 0.063767\n",
      "epoch: 52/100, loss = 0.063662\n",
      "epoch: 53/100, loss = 0.062716\n",
      "epoch: 54/100, loss = 0.062060\n",
      "epoch: 55/100, loss = 0.061412\n",
      "epoch: 56/100, loss = 0.060536\n",
      "epoch: 57/100, loss = 0.060250\n",
      "epoch: 58/100, loss = 0.059809\n",
      "epoch: 59/100, loss = 0.059341\n",
      "epoch: 60/100, loss = 0.058466\n",
      "epoch: 61/100, loss = 0.058129\n",
      "epoch: 62/100, loss = 0.057803\n",
      "epoch: 63/100, loss = 0.056974\n",
      "epoch: 64/100, loss = 0.056863\n",
      "epoch: 65/100, loss = 0.056492\n",
      "epoch: 66/100, loss = 0.055894\n",
      "epoch: 67/100, loss = 0.055417\n",
      "epoch: 68/100, loss = 0.054760\n",
      "epoch: 69/100, loss = 0.054357\n",
      "epoch: 70/100, loss = 0.054054\n",
      "epoch: 71/100, loss = 0.053473\n",
      "epoch: 72/100, loss = 0.053262\n",
      "epoch: 73/100, loss = 0.053044\n",
      "epoch: 74/100, loss = 0.052165\n",
      "epoch: 75/100, loss = 0.052050\n",
      "epoch: 76/100, loss = 0.052061\n",
      "epoch: 77/100, loss = 0.051378\n",
      "epoch: 78/100, loss = 0.050958\n",
      "epoch: 79/100, loss = 0.050578\n",
      "epoch: 80/100, loss = 0.050435\n",
      "epoch: 81/100, loss = 0.050187\n",
      "epoch: 82/100, loss = 0.049654\n",
      "epoch: 83/100, loss = 0.049007\n",
      "epoch: 84/100, loss = 0.049057\n",
      "epoch: 85/100, loss = 0.048341\n",
      "epoch: 86/100, loss = 0.048590\n",
      "epoch: 87/100, loss = 0.048116\n",
      "epoch: 88/100, loss = 0.047129\n",
      "epoch: 89/100, loss = 0.047092\n",
      "epoch: 90/100, loss = 0.046971\n",
      "epoch: 91/100, loss = 0.046645\n",
      "epoch: 92/100, loss = 0.046147\n",
      "epoch: 93/100, loss = 0.045624\n",
      "epoch: 94/100, loss = 0.045634\n",
      "epoch: 95/100, loss = 0.045263\n",
      "epoch: 96/100, loss = 0.044881\n",
      "epoch: 97/100, loss = 0.044741\n",
      "epoch: 98/100, loss = 0.044477\n",
      "epoch: 99/100, loss = 0.044325\n",
      "epoch: 100/100, loss = 0.043872\n"
     ]
    }
   ],
   "source": [
    "class AllToCategorialAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(df.columns), 9),\n",
    "            torch.nn.BatchNorm1d(9),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(9, 4),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, len(categorial_columns)),\n",
    "            torch.nn.BatchNorm1d(len(categorial_columns)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "all_to_cat_model = AllToCategorialAE()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(all_to_cat_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    all_to_cat_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for cat, cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = all_to_cat_model(torch.cat((cat, cont), 1))\n",
    "        train_loss = criterion(outputs,  cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:40.531887100Z",
     "start_time": "2023-06-14T10:47:38.238558200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.29795331, 0.49451137, 0.45338643, ..., 0.63380282, 0.55681818,\n        0.        ],\n       [0.75777566, 0.22989401, 0.55975157, ..., 0.33802817, 0.46590909,\n        1.        ],\n       [0.73622459, 0.21030919, 0.56186223, ..., 0.48591549, 0.59090909,\n        0.66666667],\n       ...,\n       [0.66906512, 0.52333385, 0.42955545, ..., 0.28169014, 0.29545455,\n        0.24873737],\n       [0.36839759, 0.74466068, 0.21922338, ..., 0.53706103, 0.40198864,\n        0.24873737],\n       [0.65290588, 0.33600339, 0.52168715, ..., 0.23239437, 0.29545455,\n        0.24873737]])"
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = all_to_cat_model.encoder(torch.tensor(df.values, dtype=torch.float)).detach().numpy()\n",
    "features = np.concatenate((cat_features, df[cont_columns].values), 1)\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:40.541183300Z",
     "start_time": "2023-06-14T10:47:40.533892300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "def cluster_accuracy(y_pred, y_true):\n",
    "    # We need to map the labels to our cluster labels\n",
    "    # This is a linear assignment problem on a bipartite graph\n",
    "    k = max(len(np.unique(y_pred)), len(np.unique(y_pred)))\n",
    "    cost_matrix = np.zeros((k, k))\n",
    "    for i in range(y_pred.size):\n",
    "        cost_matrix[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix.max() - cost_matrix)\n",
    "    return cost_matrix[row_ind, col_ind].sum() / y_pred.size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:40.548639500Z",
     "start_time": "2023-06-14T10:47:40.543383800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "0.36511919698870765"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(features)\n",
    "all_to_cat_acc = cluster_accuracy(kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "all_to_cat_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:40.587094400Z",
     "start_time": "2023-06-14T10:47:40.549639200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.182464\n",
      "epoch: 2/100, loss = 0.175826\n",
      "epoch: 3/100, loss = 0.169045\n",
      "epoch: 4/100, loss = 0.163160\n",
      "epoch: 5/100, loss = 0.157447\n",
      "epoch: 6/100, loss = 0.152628\n",
      "epoch: 7/100, loss = 0.147763\n",
      "epoch: 8/100, loss = 0.143402\n",
      "epoch: 9/100, loss = 0.139230\n",
      "epoch: 10/100, loss = 0.135305\n",
      "epoch: 11/100, loss = 0.131502\n",
      "epoch: 12/100, loss = 0.128396\n",
      "epoch: 13/100, loss = 0.125053\n",
      "epoch: 14/100, loss = 0.121428\n",
      "epoch: 15/100, loss = 0.118494\n",
      "epoch: 16/100, loss = 0.115835\n",
      "epoch: 17/100, loss = 0.113186\n",
      "epoch: 18/100, loss = 0.110622\n",
      "epoch: 19/100, loss = 0.107821\n",
      "epoch: 20/100, loss = 0.105647\n",
      "epoch: 21/100, loss = 0.103144\n",
      "epoch: 22/100, loss = 0.101193\n",
      "epoch: 23/100, loss = 0.099079\n",
      "epoch: 24/100, loss = 0.096911\n",
      "epoch: 25/100, loss = 0.094654\n",
      "epoch: 26/100, loss = 0.093247\n",
      "epoch: 27/100, loss = 0.091050\n",
      "epoch: 28/100, loss = 0.089972\n",
      "epoch: 29/100, loss = 0.088488\n",
      "epoch: 30/100, loss = 0.087027\n",
      "epoch: 31/100, loss = 0.085404\n",
      "epoch: 32/100, loss = 0.084369\n",
      "epoch: 33/100, loss = 0.082787\n",
      "epoch: 34/100, loss = 0.081308\n",
      "epoch: 35/100, loss = 0.080111\n",
      "epoch: 36/100, loss = 0.079116\n",
      "epoch: 37/100, loss = 0.077954\n",
      "epoch: 38/100, loss = 0.077229\n",
      "epoch: 39/100, loss = 0.076031\n",
      "epoch: 40/100, loss = 0.075208\n",
      "epoch: 41/100, loss = 0.074403\n",
      "epoch: 42/100, loss = 0.073114\n",
      "epoch: 43/100, loss = 0.072104\n",
      "epoch: 44/100, loss = 0.071426\n",
      "epoch: 45/100, loss = 0.070173\n",
      "epoch: 46/100, loss = 0.069384\n",
      "epoch: 47/100, loss = 0.068830\n",
      "epoch: 48/100, loss = 0.068330\n",
      "epoch: 49/100, loss = 0.067333\n",
      "epoch: 50/100, loss = 0.066922\n",
      "epoch: 51/100, loss = 0.066135\n",
      "epoch: 52/100, loss = 0.065208\n",
      "epoch: 53/100, loss = 0.064417\n",
      "epoch: 54/100, loss = 0.064030\n",
      "epoch: 55/100, loss = 0.063237\n",
      "epoch: 56/100, loss = 0.062641\n",
      "epoch: 57/100, loss = 0.061884\n",
      "epoch: 58/100, loss = 0.061430\n",
      "epoch: 59/100, loss = 0.060546\n",
      "epoch: 60/100, loss = 0.060208\n",
      "epoch: 61/100, loss = 0.060018\n",
      "epoch: 62/100, loss = 0.059259\n",
      "epoch: 63/100, loss = 0.058737\n",
      "epoch: 64/100, loss = 0.058511\n",
      "epoch: 65/100, loss = 0.057401\n",
      "epoch: 66/100, loss = 0.057405\n",
      "epoch: 67/100, loss = 0.056659\n",
      "epoch: 68/100, loss = 0.056056\n",
      "epoch: 69/100, loss = 0.055846\n",
      "epoch: 70/100, loss = 0.055122\n",
      "epoch: 71/100, loss = 0.054396\n",
      "epoch: 72/100, loss = 0.054186\n",
      "epoch: 73/100, loss = 0.053956\n",
      "epoch: 74/100, loss = 0.053234\n",
      "epoch: 75/100, loss = 0.052983\n",
      "epoch: 76/100, loss = 0.052459\n",
      "epoch: 77/100, loss = 0.051798\n",
      "epoch: 78/100, loss = 0.051870\n",
      "epoch: 79/100, loss = 0.051435\n",
      "epoch: 80/100, loss = 0.050892\n",
      "epoch: 81/100, loss = 0.050579\n",
      "epoch: 82/100, loss = 0.050198\n",
      "epoch: 83/100, loss = 0.050004\n",
      "epoch: 84/100, loss = 0.049333\n",
      "epoch: 85/100, loss = 0.048824\n",
      "epoch: 86/100, loss = 0.048724\n",
      "epoch: 87/100, loss = 0.048145\n",
      "epoch: 88/100, loss = 0.047944\n",
      "epoch: 89/100, loss = 0.047460\n",
      "epoch: 90/100, loss = 0.047403\n",
      "epoch: 91/100, loss = 0.046816\n",
      "epoch: 92/100, loss = 0.047226\n",
      "epoch: 93/100, loss = 0.046337\n",
      "epoch: 94/100, loss = 0.045721\n",
      "epoch: 95/100, loss = 0.045712\n",
      "epoch: 96/100, loss = 0.045301\n",
      "epoch: 97/100, loss = 0.045286\n",
      "epoch: 98/100, loss = 0.044614\n",
      "epoch: 99/100, loss = 0.044538\n",
      "epoch: 100/100, loss = 0.043956\n"
     ]
    }
   ],
   "source": [
    "class OnlyCategorialAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(categorial_columns), 4),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, len(categorial_columns)),\n",
    "            torch.nn.BatchNorm1d(len(categorial_columns)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "cat_to_cat_model = OnlyCategorialAE()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cat_to_cat_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cat_to_cat_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for cat, cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cat_to_cat_model(cat)\n",
    "        train_loss = criterion(outputs,  cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:42.543928500Z",
     "start_time": "2023-06-14T10:47:40.564559300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "0.38143036386449186"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = cat_to_cat_model.encoder(torch.tensor(df[categorial_columns].values, dtype=torch.float)).detach().numpy()\n",
    "features = np.concatenate((cat_features, df[cont_columns].values), 1)\n",
    "kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(features)\n",
    "cat_to_cat_acc = cluster_accuracy(kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "cat_to_cat_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:42.561841700Z",
     "start_time": "2023-06-14T10:47:42.547278200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Cols to Categorial Cols AE: 0.36511919698870765\n",
      "Categorial Cols to Categorial Cols AE: 0.38143036386449186\n"
     ]
    }
   ],
   "source": [
    "print(f\"All Cols to Categorial Cols AE: {all_to_cat_acc}\")\n",
    "print(f\"Categorial Cols to Categorial Cols AE: {cat_to_cat_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:42.565599400Z",
     "start_time": "2023-06-14T10:47:42.560832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T10:47:42.570445400Z",
     "start_time": "2023-06-14T10:47:42.568436600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
