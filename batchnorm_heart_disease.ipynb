{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:17.186396300Z",
     "start_time": "2023-06-19T16:25:17.129926300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "     age     sex               cp  trestbps   chol    fbs           restecg   \n0     63    Male   typical angina     145.0  233.0   True    lv hypertrophy  \\\n1     67    Male     asymptomatic     160.0  286.0  False    lv hypertrophy   \n2     67    Male     asymptomatic     120.0  229.0  False    lv hypertrophy   \n3     37    Male      non-anginal     130.0  250.0  False            normal   \n6     62  Female     asymptomatic     140.0  268.0  False    lv hypertrophy   \n..   ...     ...              ...       ...    ...    ...               ...   \n915   54  Female     asymptomatic     127.0  333.0   True  st-t abnormality   \n916   62    Male   typical angina       NaN  139.0  False  st-t abnormality   \n917   55    Male     asymptomatic     122.0  223.0   True  st-t abnormality   \n918   58    Male     asymptomatic       NaN  385.0   True    lv hypertrophy   \n919   62    Male  atypical angina     120.0  254.0  False    lv hypertrophy   \n\n     thalch  exang  oldpeak        slope   ca               thal  num  \n0     150.0  False      2.3  downsloping  0.0       fixed defect    0  \n1     108.0   True      1.5         flat  3.0             normal    2  \n2     129.0   True      2.6         flat  2.0  reversable defect    1  \n3     187.0  False      3.5  downsloping  0.0             normal    0  \n6     160.0  False      3.6  downsloping  2.0             normal    3  \n..      ...    ...      ...          ...  ...                ...  ...  \n915   154.0  False      0.0          NaN  NaN                NaN    1  \n916     NaN    NaN      NaN          NaN  NaN                NaN    0  \n917   100.0  False      0.0          NaN  NaN       fixed defect    2  \n918     NaN    NaN      NaN          NaN  NaN                NaN    0  \n919    93.0   True      0.0          NaN  NaN                NaN    1  \n\n[797 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n      <th>num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>Male</td>\n      <td>typical angina</td>\n      <td>145.0</td>\n      <td>233.0</td>\n      <td>True</td>\n      <td>lv hypertrophy</td>\n      <td>150.0</td>\n      <td>False</td>\n      <td>2.3</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>fixed defect</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>160.0</td>\n      <td>286.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>108.0</td>\n      <td>True</td>\n      <td>1.5</td>\n      <td>flat</td>\n      <td>3.0</td>\n      <td>normal</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>120.0</td>\n      <td>229.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>129.0</td>\n      <td>True</td>\n      <td>2.6</td>\n      <td>flat</td>\n      <td>2.0</td>\n      <td>reversable defect</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>Male</td>\n      <td>non-anginal</td>\n      <td>130.0</td>\n      <td>250.0</td>\n      <td>False</td>\n      <td>normal</td>\n      <td>187.0</td>\n      <td>False</td>\n      <td>3.5</td>\n      <td>downsloping</td>\n      <td>0.0</td>\n      <td>normal</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62</td>\n      <td>Female</td>\n      <td>asymptomatic</td>\n      <td>140.0</td>\n      <td>268.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>160.0</td>\n      <td>False</td>\n      <td>3.6</td>\n      <td>downsloping</td>\n      <td>2.0</td>\n      <td>normal</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>Female</td>\n      <td>asymptomatic</td>\n      <td>127.0</td>\n      <td>333.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>154.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>typical angina</td>\n      <td>NaN</td>\n      <td>139.0</td>\n      <td>False</td>\n      <td>st-t abnormality</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>122.0</td>\n      <td>223.0</td>\n      <td>True</td>\n      <td>st-t abnormality</td>\n      <td>100.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>fixed defect</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>58</td>\n      <td>Male</td>\n      <td>asymptomatic</td>\n      <td>NaN</td>\n      <td>385.0</td>\n      <td>True</td>\n      <td>lv hypertrophy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>Male</td>\n      <td>atypical angina</td>\n      <td>120.0</td>\n      <td>254.0</td>\n      <td>False</td>\n      <td>lv hypertrophy</td>\n      <td>93.0</td>\n      <td>True</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = pd.read_csv(\"datasets/heart_disease_uci.csv\")\n",
    "og_df.drop(columns=[\"id\", \"dataset\"], inplace=True)\n",
    "og_df = og_df.drop(og_df[og_df[\"num\"] == 0].sample(frac=0.3).index)\n",
    "og_df # this df still has \"num\" -> the target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:17.192390500Z",
     "start_time": "2023-06-19T16:25:17.137318300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "categorial_columns = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"thal\"]\n",
    "cont_columns = [\"age\", \"trestbps\", \"chol\", \"thalch\", \"oldpeak\", \"ca\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:17.192390500Z",
     "start_time": "2023-06-19T16:25:17.170172700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "          age  sex        cp  trestbps      chol  fbs   restecg    thalch   \n0    0.714286  1.0  1.000000  0.725000  0.386401  0.5  0.000000  0.666667  \\\n1    0.795918  1.0  0.000000  0.800000  0.474295  0.0  0.000000  0.355556   \n2    0.795918  1.0  0.000000  0.600000  0.379768  0.0  0.000000  0.511111   \n3    0.183673  1.0  0.666667  0.650000  0.414594  0.0  0.333333  0.940741   \n6    0.693878  0.0  0.000000  0.700000  0.444444  0.0  0.000000  0.740741   \n..        ...  ...       ...       ...       ...  ...       ...       ...   \n915  0.530612  0.0  0.000000  0.635000  0.552239  0.5  0.666667  0.696296   \n916  0.693878  1.0  1.000000  0.661433  0.230514  0.0  0.666667  0.561664   \n917  0.551020  1.0  0.000000  0.610000  0.369818  0.5  0.666667  0.296296   \n918  0.612245  1.0  0.000000  0.661433  0.638474  0.5  0.000000  0.561664   \n919  0.693878  1.0  0.333333  0.600000  0.421227  0.0  0.000000  0.244444   \n\n     exang   oldpeak     slope        ca      thal  \n0      0.0  0.556818  0.000000  0.000000  0.000000  \n1      0.5  0.465909  0.333333  1.000000  0.333333  \n2      0.5  0.590909  0.333333  0.666667  0.666667  \n3      0.0  0.693182  0.000000  0.000000  0.333333  \n6      0.0  0.704545  0.000000  0.666667  0.333333  \n..     ...       ...       ...       ...       ...  \n915    0.0  0.295455  1.000000  0.252564  1.000000  \n916    1.0  0.403732  1.000000  0.252564  1.000000  \n917    0.0  0.295455  1.000000  0.252564  0.000000  \n918    1.0  0.403732  1.000000  0.252564  1.000000  \n919    0.5  0.295455  1.000000  0.252564  1.000000  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.714286</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.725000</td>\n      <td>0.386401</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.556818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.800000</td>\n      <td>0.474295</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.355556</td>\n      <td>0.5</td>\n      <td>0.465909</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.795918</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.600000</td>\n      <td>0.379768</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.511111</td>\n      <td>0.5</td>\n      <td>0.590909</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.183673</td>\n      <td>1.0</td>\n      <td>0.666667</td>\n      <td>0.650000</td>\n      <td>0.414594</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>0.940741</td>\n      <td>0.0</td>\n      <td>0.693182</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.693878</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.700000</td>\n      <td>0.444444</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.740741</td>\n      <td>0.0</td>\n      <td>0.704545</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>0.530612</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.635000</td>\n      <td>0.552239</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.696296</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.252564</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.661433</td>\n      <td>0.230514</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.561664</td>\n      <td>1.0</td>\n      <td>0.403732</td>\n      <td>1.000000</td>\n      <td>0.252564</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>0.551020</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.610000</td>\n      <td>0.369818</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.296296</td>\n      <td>0.0</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.252564</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>0.612245</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.661433</td>\n      <td>0.638474</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.561664</td>\n      <td>1.0</td>\n      <td>0.403732</td>\n      <td>1.000000</td>\n      <td>0.252564</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>0.693878</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.600000</td>\n      <td>0.421227</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.244444</td>\n      <td>0.5</td>\n      <td>0.295455</td>\n      <td>1.000000</td>\n      <td>0.252564</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min_max = og_df.copy()\n",
    "df_min_max.drop(columns=\"num\", inplace=True)\n",
    "df_min_max[categorial_columns] = df_min_max[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df_min_max[categorial_columns] = MinMaxScaler().fit_transform(df_min_max[categorial_columns])\n",
    "\n",
    "df_min_max[cont_columns] = MinMaxScaler().fit_transform(df_min_max[cont_columns])\n",
    "df_min_max = df_min_max.fillna(df_min_max.mean())\n",
    "df_min_max"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:17.205586800Z",
     "start_time": "2023-06-19T16:25:17.174171600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class HeartDiseaseDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.cat = torch.tensor(df[categorial_columns].values, dtype=torch.float)\n",
    "        self.cont = torch.tensor(df[cont_columns].values, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cat[idx], self.cont[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cat.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:17.213768500Z",
     "start_time": "2023-06-19T16:25:17.210975700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "797"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = HeartDiseaseDataset(df_min_max)\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:17.247977300Z",
     "start_time": "2023-06-19T16:25:17.215770600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.196394\n",
      "epoch: 2/100, loss = 0.185074\n",
      "epoch: 3/100, loss = 0.173884\n",
      "epoch: 4/100, loss = 0.163533\n",
      "epoch: 5/100, loss = 0.154022\n",
      "epoch: 6/100, loss = 0.145754\n",
      "epoch: 7/100, loss = 0.138484\n",
      "epoch: 8/100, loss = 0.132338\n",
      "epoch: 9/100, loss = 0.126797\n",
      "epoch: 10/100, loss = 0.122130\n",
      "epoch: 11/100, loss = 0.118086\n",
      "epoch: 12/100, loss = 0.114530\n",
      "epoch: 13/100, loss = 0.110691\n",
      "epoch: 14/100, loss = 0.108210\n",
      "epoch: 15/100, loss = 0.105490\n",
      "epoch: 16/100, loss = 0.102652\n",
      "epoch: 17/100, loss = 0.100232\n",
      "epoch: 18/100, loss = 0.098008\n",
      "epoch: 19/100, loss = 0.096104\n",
      "epoch: 20/100, loss = 0.094351\n",
      "epoch: 21/100, loss = 0.092399\n",
      "epoch: 22/100, loss = 0.090680\n",
      "epoch: 23/100, loss = 0.089651\n",
      "epoch: 24/100, loss = 0.087711\n",
      "epoch: 25/100, loss = 0.086844\n",
      "epoch: 26/100, loss = 0.084831\n",
      "epoch: 27/100, loss = 0.083860\n",
      "epoch: 28/100, loss = 0.082296\n",
      "epoch: 29/100, loss = 0.081470\n",
      "epoch: 30/100, loss = 0.080155\n",
      "epoch: 31/100, loss = 0.079210\n",
      "epoch: 32/100, loss = 0.077699\n",
      "epoch: 33/100, loss = 0.077117\n",
      "epoch: 34/100, loss = 0.075829\n",
      "epoch: 35/100, loss = 0.074669\n",
      "epoch: 36/100, loss = 0.073833\n",
      "epoch: 37/100, loss = 0.073001\n",
      "epoch: 38/100, loss = 0.071946\n",
      "epoch: 39/100, loss = 0.070816\n",
      "epoch: 40/100, loss = 0.070624\n",
      "epoch: 41/100, loss = 0.068952\n",
      "epoch: 42/100, loss = 0.068165\n",
      "epoch: 43/100, loss = 0.067604\n",
      "epoch: 44/100, loss = 0.067074\n",
      "epoch: 45/100, loss = 0.065769\n",
      "epoch: 46/100, loss = 0.065371\n",
      "epoch: 47/100, loss = 0.064819\n",
      "epoch: 48/100, loss = 0.063746\n",
      "epoch: 49/100, loss = 0.062935\n",
      "epoch: 50/100, loss = 0.062316\n",
      "epoch: 51/100, loss = 0.061447\n",
      "epoch: 52/100, loss = 0.061299\n",
      "epoch: 53/100, loss = 0.060577\n",
      "epoch: 54/100, loss = 0.059753\n",
      "epoch: 55/100, loss = 0.059210\n",
      "epoch: 56/100, loss = 0.058588\n",
      "epoch: 57/100, loss = 0.058892\n",
      "epoch: 58/100, loss = 0.057718\n",
      "epoch: 59/100, loss = 0.056771\n",
      "epoch: 60/100, loss = 0.056561\n",
      "epoch: 61/100, loss = 0.055728\n",
      "epoch: 62/100, loss = 0.055665\n",
      "epoch: 63/100, loss = 0.055037\n",
      "epoch: 64/100, loss = 0.054382\n",
      "epoch: 65/100, loss = 0.054215\n",
      "epoch: 66/100, loss = 0.053711\n",
      "epoch: 67/100, loss = 0.053101\n",
      "epoch: 68/100, loss = 0.052626\n",
      "epoch: 69/100, loss = 0.052089\n",
      "epoch: 70/100, loss = 0.052177\n",
      "epoch: 71/100, loss = 0.051443\n",
      "epoch: 72/100, loss = 0.051177\n",
      "epoch: 73/100, loss = 0.050500\n",
      "epoch: 74/100, loss = 0.049824\n",
      "epoch: 75/100, loss = 0.049958\n",
      "epoch: 76/100, loss = 0.049370\n",
      "epoch: 77/100, loss = 0.048773\n",
      "epoch: 78/100, loss = 0.049331\n",
      "epoch: 79/100, loss = 0.048328\n",
      "epoch: 80/100, loss = 0.048520\n",
      "epoch: 81/100, loss = 0.047862\n",
      "epoch: 82/100, loss = 0.046969\n",
      "epoch: 83/100, loss = 0.046870\n",
      "epoch: 84/100, loss = 0.046424\n",
      "epoch: 85/100, loss = 0.046053\n",
      "epoch: 86/100, loss = 0.046101\n",
      "epoch: 87/100, loss = 0.045987\n",
      "epoch: 88/100, loss = 0.045189\n",
      "epoch: 89/100, loss = 0.044646\n",
      "epoch: 90/100, loss = 0.044454\n",
      "epoch: 91/100, loss = 0.044153\n",
      "epoch: 92/100, loss = 0.043872\n",
      "epoch: 93/100, loss = 0.043533\n",
      "epoch: 94/100, loss = 0.043687\n",
      "epoch: 95/100, loss = 0.042867\n",
      "epoch: 96/100, loss = 0.042859\n",
      "epoch: 97/100, loss = 0.042600\n",
      "epoch: 98/100, loss = 0.042499\n",
      "epoch: 99/100, loss = 0.042268\n",
      "epoch: 100/100, loss = 0.041983\n"
     ]
    }
   ],
   "source": [
    "class AllToCategorialAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(df_min_max.columns), 9),\n",
    "            torch.nn.BatchNorm1d(9),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(9, 4),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, len(categorial_columns)),\n",
    "            torch.nn.BatchNorm1d(len(categorial_columns)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "all_to_cat_model = AllToCategorialAE()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(all_to_cat_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    all_to_cat_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for cat, cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = all_to_cat_model(torch.cat((cat, cont), 1))\n",
    "        train_loss = criterion(outputs,  cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:19.671515900Z",
     "start_time": "2023-06-19T16:25:17.228173500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.57319617, 0.39101484, 0.72134006, ..., 0.66666667, 0.55681818,\n        0.        ],\n       [0.22031595, 0.31446555, 0.36246598, ..., 0.35555556, 0.46590909,\n        1.        ],\n       [0.17055316, 0.21436307, 0.33376518, ..., 0.51111111, 0.59090909,\n        0.66666667],\n       ...,\n       [0.54392433, 0.7908566 , 0.53421348, ..., 0.2962963 , 0.29545455,\n        0.2525641 ],\n       [0.24430327, 0.51297486, 0.58800972, ..., 0.56166394, 0.40373157,\n        0.2525641 ],\n       [0.20519525, 0.17199433, 0.44757509, ..., 0.24444444, 0.29545455,\n        0.2525641 ]])"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = all_to_cat_model.encoder(torch.tensor(df_min_max.values, dtype=torch.float)).detach().numpy()\n",
    "features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:19.680727300Z",
     "start_time": "2023-06-19T16:25:19.672544500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def cluster_accuracy(y_pred, y_true):\n",
    "    # We need to map the labels to our cluster labels\n",
    "    # This is a linear assignment problem on a bipartite graph\n",
    "    k = max(len(np.unique(y_pred)), len(np.unique(y_pred)))\n",
    "    cost_matrix = np.zeros((k, k))\n",
    "    for i in range(y_pred.size):\n",
    "        cost_matrix[y_pred[i], y_true[i]] += 1\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix.max() - cost_matrix)\n",
    "    return cost_matrix[row_ind, col_ind].sum() / y_pred.size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:19.690525300Z",
     "start_time": "2023-06-19T16:25:19.683203100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3186951066499373"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(features)\n",
    "all_to_cat_acc = cluster_accuracy(kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "all_to_cat_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:19.709770100Z",
     "start_time": "2023-06-19T16:25:19.692526200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 0.203300\n",
      "epoch: 2/100, loss = 0.197388\n",
      "epoch: 3/100, loss = 0.191051\n",
      "epoch: 4/100, loss = 0.185135\n",
      "epoch: 5/100, loss = 0.179607\n",
      "epoch: 6/100, loss = 0.174116\n",
      "epoch: 7/100, loss = 0.168146\n",
      "epoch: 8/100, loss = 0.162484\n",
      "epoch: 9/100, loss = 0.156702\n",
      "epoch: 10/100, loss = 0.150947\n",
      "epoch: 11/100, loss = 0.145555\n",
      "epoch: 12/100, loss = 0.139701\n",
      "epoch: 13/100, loss = 0.134431\n",
      "epoch: 14/100, loss = 0.129597\n",
      "epoch: 15/100, loss = 0.125407\n",
      "epoch: 16/100, loss = 0.120979\n",
      "epoch: 17/100, loss = 0.117098\n",
      "epoch: 18/100, loss = 0.113676\n",
      "epoch: 19/100, loss = 0.110161\n",
      "epoch: 20/100, loss = 0.106272\n",
      "epoch: 21/100, loss = 0.103127\n",
      "epoch: 22/100, loss = 0.101138\n",
      "epoch: 23/100, loss = 0.098119\n",
      "epoch: 24/100, loss = 0.095774\n",
      "epoch: 25/100, loss = 0.093919\n",
      "epoch: 26/100, loss = 0.091951\n",
      "epoch: 27/100, loss = 0.090379\n",
      "epoch: 28/100, loss = 0.088500\n",
      "epoch: 29/100, loss = 0.087609\n",
      "epoch: 30/100, loss = 0.086223\n",
      "epoch: 31/100, loss = 0.084470\n",
      "epoch: 32/100, loss = 0.083409\n",
      "epoch: 33/100, loss = 0.082512\n",
      "epoch: 34/100, loss = 0.080926\n",
      "epoch: 35/100, loss = 0.080086\n",
      "epoch: 36/100, loss = 0.079167\n",
      "epoch: 37/100, loss = 0.078235\n",
      "epoch: 38/100, loss = 0.077014\n",
      "epoch: 39/100, loss = 0.076119\n",
      "epoch: 40/100, loss = 0.075096\n",
      "epoch: 41/100, loss = 0.074517\n",
      "epoch: 42/100, loss = 0.073579\n",
      "epoch: 43/100, loss = 0.073124\n",
      "epoch: 44/100, loss = 0.072011\n",
      "epoch: 45/100, loss = 0.071791\n",
      "epoch: 46/100, loss = 0.070415\n",
      "epoch: 47/100, loss = 0.070437\n",
      "epoch: 48/100, loss = 0.069216\n",
      "epoch: 49/100, loss = 0.068727\n",
      "epoch: 50/100, loss = 0.068171\n",
      "epoch: 51/100, loss = 0.067140\n",
      "epoch: 52/100, loss = 0.066407\n",
      "epoch: 53/100, loss = 0.065811\n",
      "epoch: 54/100, loss = 0.065566\n",
      "epoch: 55/100, loss = 0.064737\n",
      "epoch: 56/100, loss = 0.064132\n",
      "epoch: 57/100, loss = 0.063610\n",
      "epoch: 58/100, loss = 0.063256\n",
      "epoch: 59/100, loss = 0.062521\n",
      "epoch: 60/100, loss = 0.061981\n",
      "epoch: 61/100, loss = 0.061010\n",
      "epoch: 62/100, loss = 0.061087\n",
      "epoch: 63/100, loss = 0.060099\n",
      "epoch: 64/100, loss = 0.059980\n",
      "epoch: 65/100, loss = 0.059217\n",
      "epoch: 66/100, loss = 0.058657\n",
      "epoch: 67/100, loss = 0.058377\n",
      "epoch: 68/100, loss = 0.057243\n",
      "epoch: 69/100, loss = 0.056840\n",
      "epoch: 70/100, loss = 0.056214\n",
      "epoch: 71/100, loss = 0.056081\n",
      "epoch: 72/100, loss = 0.055316\n",
      "epoch: 73/100, loss = 0.054656\n",
      "epoch: 74/100, loss = 0.054335\n",
      "epoch: 75/100, loss = 0.054164\n",
      "epoch: 76/100, loss = 0.053173\n",
      "epoch: 77/100, loss = 0.052493\n",
      "epoch: 78/100, loss = 0.052295\n",
      "epoch: 79/100, loss = 0.051806\n",
      "epoch: 80/100, loss = 0.051357\n",
      "epoch: 81/100, loss = 0.051154\n",
      "epoch: 82/100, loss = 0.050485\n",
      "epoch: 83/100, loss = 0.050229\n",
      "epoch: 84/100, loss = 0.049606\n",
      "epoch: 85/100, loss = 0.049207\n",
      "epoch: 86/100, loss = 0.048791\n",
      "epoch: 87/100, loss = 0.048412\n",
      "epoch: 88/100, loss = 0.047965\n",
      "epoch: 89/100, loss = 0.047510\n",
      "epoch: 90/100, loss = 0.047329\n",
      "epoch: 91/100, loss = 0.046912\n",
      "epoch: 92/100, loss = 0.046431\n",
      "epoch: 93/100, loss = 0.046033\n",
      "epoch: 94/100, loss = 0.045662\n",
      "epoch: 95/100, loss = 0.045567\n",
      "epoch: 96/100, loss = 0.045127\n",
      "epoch: 97/100, loss = 0.044809\n",
      "epoch: 98/100, loss = 0.044188\n",
      "epoch: 99/100, loss = 0.044032\n",
      "epoch: 100/100, loss = 0.043748\n"
     ]
    }
   ],
   "source": [
    "class OnlyCategorialAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(categorial_columns), 4),\n",
    "            torch.nn.BatchNorm1d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, len(categorial_columns)),\n",
    "            torch.nn.BatchNorm1d(len(categorial_columns)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "cat_to_cat_model = OnlyCategorialAE()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(cat_to_cat_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cat_to_cat_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for cat, cont in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cat_to_cat_model(cat)\n",
    "        train_loss = criterion(outputs,  cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:21.603297300Z",
     "start_time": "2023-06-19T16:25:19.713771500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "0.3851944792973651"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = cat_to_cat_model.encoder(torch.tensor(df_min_max[categorial_columns].values, dtype=torch.float)).detach().numpy()\n",
    "features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(features)\n",
    "cat_to_cat_acc = cluster_accuracy(kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "cat_to_cat_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:21.623547800Z",
     "start_time": "2023-06-19T16:25:21.606766Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "     age  sex  cp    trestbps   chol  fbs  restecg      thalch  exang   \n0     63    1   3  145.000000  233.0    1        0  150.000000      0  \\\n1     67    1   0  160.000000  286.0    0        0  108.000000      1   \n2     67    1   0  120.000000  229.0    0        0  129.000000      1   \n3     37    1   2  130.000000  250.0    0        1  187.000000      0   \n6     62    0   0  140.000000  268.0    0        0  160.000000      0   \n..   ...  ...  ..         ...    ...  ...      ...         ...    ...   \n915   54    0   0  127.000000  333.0    1        2  154.000000      0   \n916   62    1   3  132.286676  139.0    0        2  135.824632      2   \n917   55    1   0  122.000000  223.0    1        2  100.000000      0   \n918   58    1   0  132.286676  385.0    1        0  135.824632      2   \n919   62    1   1  120.000000  254.0    0        0   93.000000      1   \n\n      oldpeak  slope        ca  thal  \n0    2.300000      0  0.000000     0  \n1    1.500000      1  3.000000     1  \n2    2.600000      1  2.000000     2  \n3    3.500000      0  0.000000     1  \n6    3.600000      0  2.000000     1  \n..        ...    ...       ...   ...  \n915  0.000000      3  0.757692     3  \n916  0.952838      3  0.757692     3  \n917  0.000000      3  0.757692     0  \n918  0.952838      3  0.757692     3  \n919  0.000000      3  0.757692     3  \n\n[797 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalch</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145.000000</td>\n      <td>233.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150.000000</td>\n      <td>0</td>\n      <td>2.300000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>160.000000</td>\n      <td>286.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.000000</td>\n      <td>1</td>\n      <td>1.500000</td>\n      <td>1</td>\n      <td>3.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>120.000000</td>\n      <td>229.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>129.000000</td>\n      <td>1</td>\n      <td>2.600000</td>\n      <td>1</td>\n      <td>2.000000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130.000000</td>\n      <td>250.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187.000000</td>\n      <td>0</td>\n      <td>3.500000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140.000000</td>\n      <td>268.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>160.000000</td>\n      <td>0</td>\n      <td>3.600000</td>\n      <td>0</td>\n      <td>2.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>915</th>\n      <td>54</td>\n      <td>0</td>\n      <td>0</td>\n      <td>127.000000</td>\n      <td>333.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>154.000000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>0.757692</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>62</td>\n      <td>1</td>\n      <td>3</td>\n      <td>132.286676</td>\n      <td>139.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>135.824632</td>\n      <td>2</td>\n      <td>0.952838</td>\n      <td>3</td>\n      <td>0.757692</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>55</td>\n      <td>1</td>\n      <td>0</td>\n      <td>122.000000</td>\n      <td>223.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>100.000000</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>0.757692</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>918</th>\n      <td>58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>132.286676</td>\n      <td>385.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>135.824632</td>\n      <td>2</td>\n      <td>0.952838</td>\n      <td>3</td>\n      <td>0.757692</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>919</th>\n      <td>62</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120.000000</td>\n      <td>254.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93.000000</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>3</td>\n      <td>0.757692</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>797 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_min_max = og_df.copy()\n",
    "df_no_min_max.drop(columns=\"num\", inplace=True)\n",
    "df_no_min_max[categorial_columns] = df_no_min_max[categorial_columns].apply(LabelEncoder().fit_transform)\n",
    "df_no_min_max = df_no_min_max.fillna(df_no_min_max.mean())\n",
    "df_no_min_max"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:21.678512100Z",
     "start_time": "2023-06-19T16:25:21.624550700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "797"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_min_max_dataset = HeartDiseaseDataset(df_no_min_max)\n",
    "no_min_max_dataloader = DataLoader(no_min_max_dataset, batch_size=100, shuffle=True)\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:21.687521Z",
     "start_time": "2023-06-19T16:25:21.650042600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100, loss = 1.282252\n",
      "epoch: 2/100, loss = 1.266738\n",
      "epoch: 3/100, loss = 1.250640\n",
      "epoch: 4/100, loss = 1.235710\n",
      "epoch: 5/100, loss = 1.221517\n",
      "epoch: 6/100, loss = 1.208145\n",
      "epoch: 7/100, loss = 1.195378\n",
      "epoch: 8/100, loss = 1.183441\n",
      "epoch: 9/100, loss = 1.171225\n",
      "epoch: 10/100, loss = 1.160448\n",
      "epoch: 11/100, loss = 1.150394\n",
      "epoch: 12/100, loss = 1.139788\n",
      "epoch: 13/100, loss = 1.129945\n",
      "epoch: 14/100, loss = 1.119556\n",
      "epoch: 15/100, loss = 1.110785\n",
      "epoch: 16/100, loss = 1.100845\n",
      "epoch: 17/100, loss = 1.092131\n",
      "epoch: 18/100, loss = 1.083793\n",
      "epoch: 19/100, loss = 1.075787\n",
      "epoch: 20/100, loss = 1.068824\n",
      "epoch: 21/100, loss = 1.062732\n",
      "epoch: 22/100, loss = 1.057706\n",
      "epoch: 23/100, loss = 1.052522\n",
      "epoch: 24/100, loss = 1.047738\n",
      "epoch: 25/100, loss = 1.044066\n",
      "epoch: 26/100, loss = 1.041002\n",
      "epoch: 27/100, loss = 1.037856\n",
      "epoch: 28/100, loss = 1.034254\n",
      "epoch: 29/100, loss = 1.030684\n",
      "epoch: 30/100, loss = 1.028039\n",
      "epoch: 31/100, loss = 1.025700\n",
      "epoch: 32/100, loss = 1.023235\n",
      "epoch: 33/100, loss = 1.020911\n",
      "epoch: 34/100, loss = 1.018069\n",
      "epoch: 35/100, loss = 1.016819\n",
      "epoch: 36/100, loss = 1.013590\n",
      "epoch: 37/100, loss = 1.010640\n",
      "epoch: 38/100, loss = 1.008207\n",
      "epoch: 39/100, loss = 1.006069\n",
      "epoch: 40/100, loss = 1.004038\n",
      "epoch: 41/100, loss = 1.001257\n",
      "epoch: 42/100, loss = 0.999305\n",
      "epoch: 43/100, loss = 0.996397\n",
      "epoch: 44/100, loss = 0.994545\n",
      "epoch: 45/100, loss = 0.992213\n",
      "epoch: 46/100, loss = 0.990670\n",
      "epoch: 47/100, loss = 0.988636\n",
      "epoch: 48/100, loss = 0.985753\n",
      "epoch: 49/100, loss = 0.983475\n",
      "epoch: 50/100, loss = 0.981464\n",
      "epoch: 51/100, loss = 0.980312\n",
      "epoch: 52/100, loss = 0.976909\n",
      "epoch: 53/100, loss = 0.974711\n",
      "epoch: 54/100, loss = 0.972912\n",
      "epoch: 55/100, loss = 0.971527\n",
      "epoch: 56/100, loss = 0.969625\n",
      "epoch: 57/100, loss = 0.967163\n",
      "epoch: 58/100, loss = 0.965339\n",
      "epoch: 59/100, loss = 0.964055\n",
      "epoch: 60/100, loss = 0.961670\n",
      "epoch: 61/100, loss = 0.959190\n",
      "epoch: 62/100, loss = 0.957477\n",
      "epoch: 63/100, loss = 0.956105\n",
      "epoch: 64/100, loss = 0.953632\n",
      "epoch: 65/100, loss = 0.952215\n",
      "epoch: 66/100, loss = 0.950072\n",
      "epoch: 67/100, loss = 0.947930\n",
      "epoch: 68/100, loss = 0.946819\n",
      "epoch: 69/100, loss = 0.944750\n",
      "epoch: 70/100, loss = 0.942898\n",
      "epoch: 71/100, loss = 0.941674\n",
      "epoch: 72/100, loss = 0.939302\n",
      "epoch: 73/100, loss = 0.937211\n",
      "epoch: 74/100, loss = 0.937175\n",
      "epoch: 75/100, loss = 0.935597\n",
      "epoch: 76/100, loss = 0.933064\n",
      "epoch: 77/100, loss = 0.932617\n",
      "epoch: 78/100, loss = 0.929118\n",
      "epoch: 79/100, loss = 0.928768\n",
      "epoch: 80/100, loss = 0.926993\n",
      "epoch: 81/100, loss = 0.924315\n",
      "epoch: 82/100, loss = 0.924033\n",
      "epoch: 83/100, loss = 0.922212\n",
      "epoch: 84/100, loss = 0.922192\n",
      "epoch: 85/100, loss = 0.919524\n",
      "epoch: 86/100, loss = 0.918694\n",
      "epoch: 87/100, loss = 0.916965\n",
      "epoch: 88/100, loss = 0.917067\n",
      "epoch: 89/100, loss = 0.914980\n",
      "epoch: 90/100, loss = 0.912753\n",
      "epoch: 91/100, loss = 0.912632\n",
      "epoch: 92/100, loss = 0.910627\n",
      "epoch: 93/100, loss = 0.908432\n",
      "epoch: 94/100, loss = 0.907220\n",
      "epoch: 95/100, loss = 0.908118\n",
      "epoch: 96/100, loss = 0.905277\n",
      "epoch: 97/100, loss = 0.905352\n",
      "epoch: 98/100, loss = 0.903669\n",
      "epoch: 99/100, loss = 0.902072\n",
      "epoch: 100/100, loss = 0.901168\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "no_min_max_cat_to_cat_model = OnlyCategorialAE()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(no_min_max_cat_to_cat_model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    no_min_max_cat_to_cat_model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for cat, cont in no_min_max_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = no_min_max_cat_to_cat_model(cat)\n",
    "        train_loss = criterion(outputs,  cat)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += train_loss.item()\n",
    "\n",
    "    loss = loss / len(dataloader)\n",
    "    print(\"epoch: {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:23.656595200Z",
     "start_time": "2023-06-19T16:25:21.662933900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.52008939, 0.63564682, 0.14617272, ..., 0.66666667, 0.55681818,\n        0.        ],\n       [0.57387429, 0.77381641, 0.53025556, ..., 0.35555556, 0.46590909,\n        1.        ],\n       [0.69572443, 0.71157026, 0.63199574, ..., 0.51111111, 0.59090909,\n        0.66666667],\n       ...,\n       [0.0336555 , 0.34917748, 0.39261562, ..., 0.2962963 , 0.29545455,\n        0.2525641 ],\n       [0.47608197, 0.41255972, 0.82813102, ..., 0.56166394, 0.40373157,\n        0.2525641 ],\n       [0.43759966, 0.31887686, 0.75474447, ..., 0.24444444, 0.29545455,\n        0.2525641 ]])"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = no_min_max_cat_to_cat_model.encoder(torch.tensor(df_no_min_max[categorial_columns].values, dtype=torch.float)).detach().numpy()\n",
    "features = np.concatenate((cat_features, df_min_max[cont_columns].values), 1)\n",
    "features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:23.665244500Z",
     "start_time": "2023-06-19T16:25:23.657592900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "0.39021329987452946"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=5, n_init=\"auto\", random_state=0).fit(features)\n",
    "no_min_max_acc = cluster_accuracy(kmeans.labels_, og_df[\"num\"].to_numpy())\n",
    "no_min_max_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:23.685405300Z",
     "start_time": "2023-06-19T16:25:23.667552100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Cols to Categorial Cols AE: 0.3186951066499373\n",
      "Categorial Cols to Categorial Cols AE: 0.3851944792973651\n",
      "Categorial Cols to Categorial Cols AE, No MinMax Norm: 0.39021329987452946\n"
     ]
    }
   ],
   "source": [
    "print(f\"All Cols to Categorial Cols AE: {all_to_cat_acc}\")\n",
    "print(f\"Categorial Cols to Categorial Cols AE: {cat_to_cat_acc}\")\n",
    "print(f\"Categorial Cols to Categorial Cols AE, No MinMax on Categorial Cols: {no_min_max_acc}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:23.708943400Z",
     "start_time": "2023-06-19T16:25:23.685405300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T16:25:23.709949100Z",
     "start_time": "2023-06-19T16:25:23.691428600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
