{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "from autoencoders.basic_autoencoder import BasicAutoencoder\n",
    "from autoencoders.all_to_all_autoencoder import AllToAllAutoencoder\n",
    "from autoencoders.transformer_autoencoder import TransformerAutoencoder\n",
    "from duped_modules.dcn_duped import DCNDuped\n",
    "from duped_modules.dec_duped import DECDuped\n",
    "from duped_modules.dec_duped import IDECDuped\n",
    "from load_datasets import load_all_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "torch.manual_seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "np.random.seed(0)\n",
    "\n",
    "datasets = load_all_datasets(max_rows=5000)\n",
    "accuracies = {d.name: {} for d in datasets}\n",
    "nmis = {d.name: {} for d in datasets}\n",
    "for d in datasets:\n",
    "    print(f\"{d.name}: Input dim: {d.input_dim}; Cat dim: {d.cat_dim}; Cont dim: {d.cont_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Clustering with Basic Autoencoder (no Column Embeddings)\n",
    "for d in datasets:\n",
    "    print(f\"Calculating for {d.name}...\")\n",
    "    input_dim = len(d.cat_cols) + len(d.cont_cols)\n",
    "    encoder, decoder = build_autoencoder(input_dim, input_dim, max(1, round(math.log2(d.input_dim))))\n",
    "    print(encoder, decoder)\n",
    "    ae = BasicAutoencoder(encoder, decoder, d.input_dim, d.cat_dim, d.embedding_sizes, device=device)\n",
    "    ae.fit(d.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "    dcn = DCNDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dcn.fit(d.dataloader)\n",
    "    nmis[d.name][\"No Col Emb DCN\"] = normalized_mutual_info_score(d.y, dcn.labels_)\n",
    "    accuracies[d.name][\"No Col Emb DCN\"] = cluster_accuracy(d.y, dcn.labels_)\n",
    "\n",
    "    dec = DECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dec.fit(d.dataloader)\n",
    "    nmis[d.name][\"No Col Emb DEC\"] = normalized_mutual_info_score(d.y, dec.labels_)\n",
    "    accuracies[d.name][\"No Col Emb DEC\"] = cluster_accuracy(d.y, dec.labels_)\n",
    "\n",
    "    idec = IDECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    idec.fit(d.dataloader)\n",
    "    nmis[d.name][\"No Col Emb IDEC\"] = normalized_mutual_info_score(d.y, idec.labels_)\n",
    "    accuracies[d.name][\"No Col Emb IDEC\"] = cluster_accuracy(d.y, idec.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Clustering with Column Embeddings\n",
    "for d in datasets:\n",
    "    print(f\"Calculating for {d.name}...\")\n",
    "    encoder, decoder = build_autoencoder(d.input_dim, d.input_dim, max(1, round(math.log2(d.input_dim))))\n",
    "    print(encoder, decoder)\n",
    "    ae = AllToAllAutoencoder(encoder, decoder, d.input_dim, d.cat_dim, d.embedding_sizes, device=device)\n",
    "    ae.fit(d.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "    dcn = DCNDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dcn.fit(d.dataloader)\n",
    "    nmis[d.name][\"DCN\"] = normalized_mutual_info_score(d.y, dcn.labels_)\n",
    "    accuracies[d.name][\"DCN\"] = cluster_accuracy(d.y, dcn.labels_)\n",
    "\n",
    "    dec = DECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dec.fit(d.dataloader)\n",
    "    nmis[d.name][\"DEC\"] = normalized_mutual_info_score(d.y, dec.labels_)\n",
    "    accuracies[d.name][\"DEC\"] = cluster_accuracy(d.y, dec.labels_)\n",
    "\n",
    "    idec = IDECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    idec.fit(d.dataloader)\n",
    "    nmis[d.name][\"IDEC\"] = normalized_mutual_info_score(d.y, idec.labels_)\n",
    "    accuracies[d.name][\"IDEC\"] = cluster_accuracy(d.y, idec.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Clustering with Attention\n",
    "for d in datasets:\n",
    "    print(f\"Calculating for {d.name}...\")\n",
    "    encoder, decoder = build_autoencoder(d.input_dim, d.input_dim, max(1, round(math.log2(d.input_dim))))\n",
    "    print(encoder, decoder)\n",
    "    ae = AllToAllAutoencoder(encoder, decoder, d.input_dim, d.cat_dim, d.embedding_sizes, attention=True, device=device)\n",
    "    ae.fit(d.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "    dcn = DCNDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dcn.fit(d.dataloader)\n",
    "    nmis[d.name][\"Attention DCN\"] = normalized_mutual_info_score(d.y, dcn.labels_)\n",
    "    accuracies[d.name][\"Attention DCN\"] = cluster_accuracy(d.y, dcn.labels_)\n",
    "\n",
    "    dec = DECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dec.fit(d.dataloader)\n",
    "    nmis[d.name][\"Attention DEC\"] = normalized_mutual_info_score(d.y, dec.labels_)\n",
    "    accuracies[d.name][\"Attention DEC\"] = cluster_accuracy(d.y, dec.labels_)\n",
    "\n",
    "    idec = IDECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    idec.fit(d.dataloader)\n",
    "    nmis[d.name][\"Attention IDEC\"] = normalized_mutual_info_score(d.y, idec.labels_)\n",
    "    accuracies[d.name][\"Attention IDEC\"] = cluster_accuracy(d.y, idec.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Clustering with Transformer\n",
    "for d in datasets:\n",
    "    print(f\"Calculating for {d.name}...\")\n",
    "    encoder, decoder = build_autoencoder(d.input_dim, d.input_dim, max(1, round(math.log2(d.input_dim))))\n",
    "    print(encoder, decoder)\n",
    "    ae = TransformerAutoencoder(encoder, decoder, d.input_dim, d.cat_dim, d.embedding_sizes, depth=8, device=device)\n",
    "    ae.fit(d.dataloader, n_epochs=100, lr=0.001)\n",
    "\n",
    "    dcn = DCNDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dcn.fit(d.dataloader)\n",
    "    nmis[d.name][\"Transformer DCN\"] = normalized_mutual_info_score(d.y, dcn.labels_)\n",
    "    accuracies[d.name][\"Transformer DCN\"] = cluster_accuracy(d.y, dcn.labels_)\n",
    "\n",
    "    dec = DECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    dec.fit(d.dataloader)\n",
    "    nmis[d.name][\"Transformer DEC\"] = normalized_mutual_info_score(d.y, dec.labels_)\n",
    "    accuracies[d.name][\"Transformer DEC\"] = cluster_accuracy(d.y, dec.labels_)\n",
    "\n",
    "    idec = IDECDuped(n_clusters=d.n_targets, autoencoder=ae, random_state=np.random.RandomState(0))\n",
    "    idec.fit(d.dataloader)\n",
    "    nmis[d.name][\"Transformer IDEC\"] = normalized_mutual_info_score(d.y, idec.labels_)\n",
    "    accuracies[d.name][\"Transformer IDEC\"] = cluster_accuracy(d.y, idec.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(nmis.values(), index=nmis.keys()).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(accuracies.values(), index=accuracies.keys()).round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
